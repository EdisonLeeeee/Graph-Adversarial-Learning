# AAAI
|    | Title                                                                                                | Type            | Venue                                                                                                                      | Code                                                                                       |   Year | Pubs   |
|---:|:-----------------------------------------------------------------------------------------------------|:----------------|:---------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------|-------:|:-------|
|  0 | Attacking Graph Neural Networks at Scale                                                             | âš”Attack         | [ğŸ“AAAI workshop](https://www.dropbox.com/s/ddrwoswpz3wwx40/Robust_GNNs_at_Scale__AAAI_Workshop_2020_CameraReady.pdf?dl=0) |                                                                                            |   2021 | AAAI   |
|  1 | DeHiB: Deep Hidden Backdoor Attack on Semi-Supervised Learning via Adversarial Perturbation          | âš”Attack         | [ğŸ“AAAI](https://ojs.aaai.org/index.php/AAAI/article/view/17266)                                                           |                                                                                            |   2021 | AAAI   |
|  2 | A Restricted Black-box Adversarial Framework Towards Attacking Graph Embedding Models                | âš”Attack         | [ğŸ“AAAI](https://arxiv.org/abs/1908.01297)                                                                                 | [:octocat:Code](https://github.com/SwiftieH/GFAttack)                                      |   2020 | AAAI   |
|  3 | UAG: Uncertainty-Aware Attention Graph Neural Network for Defending Adversarial Attacks              | ğŸ›¡Defense        | [ğŸ“AAAI](https://arxiv.org/abs/2009.10235)                                                                                 |                                                                                            |   2021 | AAAI   |
|  4 | Uncertainty-Matching Graph Neural Networks to Defend Against Poisoning Attacks                       | ğŸ›¡Defense        | [ğŸ“AAAI](https://arxiv.org/abs/2009.14455)                                                                                 |                                                                                            |   2021 | AAAI   |
|  5 | Power up! Robust Graph Convolutional Network against Evasion Attacks based on Graph Powering         | ğŸ›¡Defense        | [ğŸ“AAAI](https://arxiv.org/abs/1905.10029)                                                                                 | [:octocat:Code](https://www.dropbox.com/sh/p36pzx1ock2iamo/AABEr7FtM5nqwC4i9nICLIsta?dl=0) |   2021 | AAAI   |
|  6 | Personalized privacy protection in social networks through adversarial modeling                      | ğŸ›¡Defense        | [ğŸ“AAAI](https://www.cs.uic.edu/~elena/pubs/biradar-ppai21.pdf)                                                            |                                                                                            |   2021 | AAAI   |
|  7 | Randomized Generation of Adversary-Aware Fake Knowledge Graphs to Combat Intellectual Property Theft | ğŸ›¡Defense        | [ğŸ“AAAI](http://34.94.61.102/paper_AAAI-9475.html)                                                                         |                                                                                            |   2021 | AAAI   |
|  8 | Adversary for Social Good: Protecting Familial Privacy through Joint Adversarial Attacks             | ğŸ›¡Defense        | [ğŸ“AAAI](https://ojs.aaai.org//index.php/AAAI/article/view/6791)                                                           |                                                                                            |   2020 | AAAI   |
|  9 | Bayesian graph convolutional neural networks for semi-supervised classification                      | ğŸ›¡Defense        | [ğŸ“AAAI](https://arxiv.org/abs/1811.11103)                                                                                 | [:octocat:Code](https://github.com/huawei-noah/BGCN)                                       |   2019 | AAAI   |
| 10 | Improving the Robustness of Wasserstein Embedding by Adversarial PAC-Bayesian Learning               | ğŸ”Certification | [ğŸ“AAAI'2020](http://staff.ustc.edu.cn/~hexn/papers/aaai20-adversarial-embedding.pdf)                                      |                                                                                            |   2020 | AAAI   |
| 11 | DeepRobust: a Platform for Adversarial Attacks and Defenses                                          | âš™Toolbox        | [ğŸ“AAAIâ€™2021](https://ojs.aaai.org/index.php/AAAI/article/view/18017)                                                      | [**:octocat:DeepRobust**](https://github.com/DSE-MSU/DeepRobust)                           |   2021 | AAAI   |
# IJCAI
|    | Title                                                                              | Type       | Venue                                                               | Code                                                                                              |   Year | Pubs   |
|---:|:-----------------------------------------------------------------------------------|:-----------|:--------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------|-------:|:-------|
|  0 | An Efficient Adversarial Attack on Graph Structured Data                           | âš”Attack    | [ğŸ“IJCAI Workshop](https://www.aisafetyw.org/programme)             |                                                                                                   |   2020 | IJCAI  |
|  1 | An Efficient Adversarial Attack on Graph Structured Data                           | âš”Attack    | [ğŸ“IJCAI Workshop](https://www.aisafetyw.org/programme)             |                                                                                                   |   2020 | IJCAI  |
|  2 | Data Poisoning Attack against Knowledge Graph Embedding                            | âš”Attack    | [ğŸ“IJCAI](https://arxiv.org/abs/1904.12052)                         |                                                                                                   |   2019 | IJCAI  |
|  3 | Topology Attack and Defense for Graph Neural Networks: An Optimization Perspective | âš”Attack    | [ğŸ“IJCAI](https://arxiv.org/abs/1906.04214)                         | [:octocat:Code](https://github.com/KaidiXu/GCN_ADV_Train)                                         |   2019 | IJCAI  |
|  4 | Adversarial Examples on Graph Data: Deep Insights into Attack and Defense          | âš”Attack    | [ğŸ“IJCAI](https://arxiv.org/abs/1903.01610)                         | [:octocat:Code](https://github.com/stellargraph/stellargraph/tree/develop/demos/interpretability) |   2019 | IJCAI  |
|  5 | Understanding Structural Vulnerability in Graph Convolutional Networks             | ğŸ›¡Defense   | [ğŸ“IJCAI]()                                                         | [:octocat:Code](https://github.com/EdisonLeeeee/MedianGCN)                                        |   2021 | IJCAI  |
|  6 | Adversarial Examples on Graph Data: Deep Insights into Attack and Defense          | ğŸ›¡Defense   | [ğŸ“IJCAI](https://arxiv.org/abs/1903.01610)                         | [:octocat:Code](https://github.com/DSE-MSU/DeepRobust)                                            |   2019 | IJCAI  |
|  7 | Topology Attack and Defense for Graph Neural Networks: An Optimization Perspective | ğŸ›¡Defense   | [ğŸ“IJCAI](https://arxiv.org/abs/1906.04214)                         | [:octocat:Code](https://github.com/KaidiXu/GCN_ADV_Train)                                         |   2019 | IJCAI  |
|  8 | When Do GNNs Work: Understanding and Improving Neighborhood Aggregation            | âš–Stability | [ğŸ“IJCAI Workshop'2019](https://www.ijcai.org/Proceedings/2020/181) | [:octocat:Code](https://github.com/raspberryice/ala-gcn)                                          |   2019 | IJCAI  |
|  9 | Deep Graph Structure Learning for Robust Representations: A Survey                 | ğŸ“ƒSurvey   | [ğŸ“IJCAI Survey track'2021](https://arxiv.org/abs/2103.03036)       |                                                                                                   |   2021 | IJCAI  |
# ICLR
|    | Title                                                                                       | Type            | Venue                                                                 | Code                                                              |   Year | Pubs   |
|---:|:--------------------------------------------------------------------------------------------|:----------------|:----------------------------------------------------------------------|:------------------------------------------------------------------|-------:|:-------|
|  0 | One Vertex Attack on Graph Neural Networks-based Spatiotemporal Forecasting                 | âš”Attack         | [ğŸ“ICLR OpenReview](https://openreview.net/forum?id=W0MKrbVOxtd)      |                                                                   |   2020 | ICLR   |
|  1 | Single-Node Attack for Fooling Graph Neural Networks                                        | âš”Attack         | [ğŸ“ICLR OpenReview](https://openreview.net/forum?id=u4WfreuXxnk)      |                                                                   |   2020 | ICLR   |
|  2 | Black-Box Adversarial Attacks on Graph Neural Networks as An Influence Maximization Problem | âš”Attack         | [ğŸ“ICLR OpenReview](https://openreview.net/forum?id=sbyjwhxxT8K)      |                                                                   |   2020 | ICLR   |
|  3 | Learning to Deceive Knowledge Graph Augmented Models via Targeted Perturbation              | âš”Attack         | [ğŸ“ICLR](https://arxiv.org/abs/2010.12872)                            | [:octocat:Code](https://github.com/INK-USC/deceive-KG-models)     |   2020 | ICLR   |
|  4 | Backdoor Attacks to Graph Neural Networks                                                   | âš”Attack         | [ğŸ“ICLR OpenReview](https://arxiv.org/abs/2006.11165)                 |                                                                   |   2020 | ICLR   |
|  5 | Structured Adversarial Attack Towards General Implementation and Better Interpretability    | âš”Attack         | [ğŸ“ICLR](https://arxiv.org/abs/1808.01664)                            | [:octocat:Code](https://github.com/KaidiXu/StrAttack)             |   2019 | ICLR   |
|  6 | PeerNets Exploiting Peer Wisdom Against Adversarial Attacks                                 | âš”Attack         | [ğŸ“ICLR](https://arxiv.org/abs/1806.00088)                            | [:octocat:Code](https://github.com/tantara/PeerNets-pytorch)      |   2019 | ICLR   |
|  7 | Adversarial Attacks on Graph Neural Networks via Meta Learning                              | âš”Attack         | [ğŸ“ICLR](https://arxiv.org/abs/1902.08412)                            | [:octocat:Code](https://github.com/danielzuegner/gnn-meta-attack) |   2019 | ICLR   |
|  8 | Ricci-GNN: Defending Against Structural Attacks Through a Geometric Approach                | ğŸ›¡Defense        | [ğŸ“ICLR OpenReview](https://openreview.net/forum?id=_qoQkWNEhS)       |                                                                   |   2020 | ICLR   |
|  9 | Towards Robust Graph Neural Networks against Label Noise                                    | ğŸ›¡Defense        | [ğŸ“ICLR OpenReview](https://openreview.net/forum?id=H38f_9b90BO)      |                                                                   |   2020 | ICLR   |
| 10 | Graph Adversarial Networks: Protecting Information against Adversarial Attacks              | ğŸ›¡Defense        | [ğŸ“ICLR OpenReview](https://openreview.net/forum?id=Q8ZdJahesWe)      | [:octocat:Code](https://github.com/liaopeiyuan/GAL)               |   2020 | ICLR   |
| 11 | Characterizing Malicious Edges targeting on Graph Neural Networks                           | ğŸ›¡Defense        | [ğŸ“ICLR OpenReview](https://arxiv.org/abs/1906.04214)                 | [:octocat:Code](https://github.com/KaidiXu/GCN_ADV_Train)         |   2019 | ICLR   |
| 12 | Comparing and Detecting Adversarial Attacks for Graph Deep Learning                         | ğŸ›¡Defense        | [ğŸ“RLGM@ICLR](https://rlgm.github.io/papers/57.pdf)                   |                                                                   |   2019 | ICLR   |
| 13 | Collective Robustness Certificates                                                          | ğŸ”Certification | [ğŸ“ICLR'2021](https://openreview.net/forum?id=ULQdiUTHe3y)            |                                                                   |   2021 | ICLR   |
| 14 | Certifying Robustness of Graph Laplacian Based Semi-Supervised Learning                     | ğŸ”Certification | [ğŸ“ICLR OpenReview'2021](https://openreview.net/forum?id=cQyybLUoXxc) |                                                                   |   2021 | ICLR   |
# WWW
|    | Title                                                                                                               | Type            | Venue                                                         | Code                                                       |   Year | Pubs   |
|---:|:--------------------------------------------------------------------------------------------------------------------|:----------------|:--------------------------------------------------------------|:-----------------------------------------------------------|-------:|:-------|
|  0 | Adversarial Attack on Community Detection by Hiding Individuals                                                     | âš”Attack         | [ğŸ“WWW](https://arxiv.org/abs/2001.07933)                     | [:octocat:Code](https://github.com/halimiqi/CD-ATTACK)     |   2020 | WWW    |
|  1 | Non-target-specific Node Injection Attacks on Graph Neural Networks: A Hierarchical Reinforcement Learning Approach | âš”Attack         | [ğŸ“WWW](http://faculty.ist.psu.edu/vhonavar/Papers/www20.pdf) |                                                            |   2020 | WWW    |
|  2 | Robust Network Alignment via Attack Signal Scaling and Adversarial Perturbation Elimination                         | ğŸ›¡Defense        | [ğŸ“WWW](http://eng.auburn.edu/users/yangzhou/papers/RNA.pdf)  |                                                            |   2021 | WWW    |
|  3 | On the Robustness of Cascade Diffusion under Node Attacks                                                           | ğŸ›¡Defense        | [ğŸ“WWW](https://www.cs.au.dk/~karras/robustIC.pdf)            | [:octocat:Code](https://github.com/allogn/robustness)      |   2020 | WWW    |
|  4 | Friend or Faux: Graph-Based Early Detection of Fake Accounts on Social Networks                                     | ğŸ›¡Defense        | [ğŸ“WWW](https://arxiv.org/abs/2004.04834)                     |                                                            |   2020 | WWW    |
|  5 | Adversarial Training Methods for Network Embedding                                                                  | ğŸ›¡Defense        | [ğŸ“WWW](https://arxiv.org/abs/1908.11514)                     | [:octocat:Code](https://github.com/wonniu/AdvT4NE_WWW2019) |   2019 | WWW    |
|  6 | Certified Robustness of Community Detection against Adversarial Structural Perturbation via Randomized Smoothing    | ğŸ”Certification | [ğŸ“WWW'2020](https://arxiv.org/abs/2002.03421)                |                                                            |   2020 | WWW    |
# KDD
|    | Title                                                                               | Type            | Venue                                                             | Code                                                                                             |   Year | Pubs   |
|---:|:------------------------------------------------------------------------------------|:----------------|:------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------|-------:|:-------|
|  0 | Graph Adversarial Attack via Rewiring                                               | âš”Attack         | [ğŸ“KDD](https://arxiv.org/abs/1906.03750)                         |                                                                                                  |   2021 | KDD    |
|  1 | TDGIA: Effective Injection Attacks on Graph Neural Networks                         | âš”Attack         | [ğŸ“KDD](https://arxiv.org/abs/2106.06663)                         |                                                                                                  |   2021 | KDD    |
|  2 | SAGE: Intrusion Alert-driven Attack Graph Extractor                                 | âš”Attack         | [ğŸ“KDD Workshop](https://arxiv.org/abs/2107.02783)                | [:octocat:Code](https://github.com/tudelft-cda-lab/SAGE)                                         |   2021 | KDD    |
|  3 | VIKING: Adversarial Attack on Network Embeddings via Supervised Network Poisoning   | âš”Attack         | [ğŸ“PAKDD](https://arxiv.org/abs/2102.07164)                       | [:octocat:Code](https://github.com/virresh/viking)                                               |   2021 | KDD    |
|  4 | Adversarial Attacks on Graph Neural Networks: Perturbations and their Patterns      | âš”Attack         | [ğŸ“TKDD](https://dl.acm.org/doi/10.1145/3394520)                  |                                                                                                  |   2020 | KDD    |
|  5 | Scalable Attack on Graph Data by Injecting Vicious Nodes                            | âš”Attack         | [ğŸ“ECML-PKDD](https://arxiv.org/abs/2004.13825)                   |                                                                                                  |   2020 | KDD    |
|  6 | Attackability Characterization of Adversarial Evasion Attack on Discrete Data       | âš”Attack         | [ğŸ“KDD](https://dl.acm.org/doi/10.1145/3394486.3403194)           |                                                                                                  |   2020 | KDD    |
|  7 | Adversarial Attacks on Neural Networks for Graph Data                               | âš”Attack         | [ğŸ“KDD](https://arxiv.org/abs/1805.07984)                         | [:octocat:Code](https://github.com/danielzuegner/nettack)                                        |   2018 | KDD    |
|  8 | Robust Detection of Adaptive Spammers by Nash Reinforcement Learning                | ğŸ›¡Defense        | [ğŸ“KDD](https://arxiv.org/abs/2006.06069)                         | [:octocat:Code](https://github.com/YingtongDou/Nash-Detect)                                      |   2020 | KDD    |
|  9 | Graph Structure Learning for Robust Graph Neural Networks                           | ğŸ›¡Defense        | [ğŸ“KDD](https://arxiv.org/abs/2005.10203)                         | [:octocat:Code](https://github.com/DSE-MSU/DeepRobust)                                           |   2020 | KDD    |
| 10 | Robust Training of Graph Convolutional Networks via Latent Perturbation             | ğŸ›¡Defense        | [ğŸ“ECML-PKDD](https://www.cs.uic.edu/~zhangx/papers/JinZha20.pdf) |                                                                                                  |   2020 | KDD    |
| 11 | Improving Robustness to Attacks Against Vertex Classification                       | ğŸ›¡Defense        | [ğŸ“MLG@KDD](http://eliassi.org/papers/benmiller-mlg2019.pdf)      |                                                                                                  |   2019 | KDD    |
| 12 | Robust Graph Convolutional Networks Against Adversarial Attacks                     | ğŸ›¡Defense        | [ğŸ“KDD](http://pengcui.thumedialab.com/papers/RGCN.pdf)           | [:octocat:Code](https://github.com/thumanlab/nrlweb/blob/master/static/assets/download/RGCN.zip) |   2019 | KDD    |
| 13 | Certifiable Robustness of Graph Convolutional Networks under Structure Perturbation | ğŸ”Certification | [ğŸ“KDD'2020](https://dl.acm.org/doi/10.1145/3394486.3403217)      | [:octocat:Code](https://github.com/danielzuegner/robust-gcn-structure)                           |   2020 | KDD    |
| 14 | Certifiable Robustness and Robust Training for Graph Convolutional Networks         | ğŸ”Certification | [ğŸ“KDD'2019](https://arxiv.org/abs/1906.12269)                    | [:octocat:Code](https://www.kdd.in.tum.de/research/robust-gcn/)                                  |   2019 | KDD    |
| 15 | Stability and Generalization of Graph Convolutional Neural Networks                 | âš–Stability      | [ğŸ“KDD'2019](https://arxiv.org/abs/1905.01004)                    | [:octocat:Code](https://github.com/raspberryice/ala-gcn)                                         |   2019 | KDD    |
# ICML
|    | Title                                                                                                                  | Type            | Venue                                                                                                | Code                                                                    |   Year | Pubs   |
|---:|:-----------------------------------------------------------------------------------------------------------------------|:----------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------|-------:|:-------|
|  0 | Practical Adversarial Attacks on Graph Neural Networks                                                                 | âš”Attack         | [ğŸ“ICML Workshop](https://grlplus.github.io/papers/8.pdf)                                            |                                                                         |   2020 | ICML   |
|  1 | Adversarial Attacks on Node Embeddings via Graph Poisoning                                                             | âš”Attack         | [ğŸ“ICML](https://arxiv.org/abs/1809.01093)                                                           | [:octocat:Code](https://github.com/abojchevski/node_embedding_attack)   |   2019 | ICML   |
|  2 | Adversarial Attack on Graph Structured Data                                                                            | âš”Attack         | [ğŸ“ICML](https://arxiv.org/abs/1806.02371)                                                           | [:octocat:Code](https://github.com/Hanjun-Dai/graph_adversarial_attack) |   2018 | ICML   |
|  3 | Integrated Defense for Resilient Graph Matching                                                                        | ğŸ›¡Defense        | [ğŸ“ICML](http://proceedings.mlr.press/v139/ren21c/ren21c.pdf)                                        |                                                                         |   2021 | ICML   |
|  4 | Information Obfuscation of Graph Neural Network                                                                        | ğŸ›¡Defense        | [ğŸ“ICML](https://arxiv.org/pdf/2009.13504.pdf)                                                       | [:octocat:Code](https://github.com/liaopeiyuan/GAL)                     |   2021 | ICML   |
|  5 | Elastic Graph Neural Networks                                                                                          | ğŸ›¡Defense        | [ğŸ“ICML](http://proceedings.mlr.press/v139/liu21k/liu21k.pdf)                                        | [:octocat:Code](https://github.com/lxiaorui/ElasticGNN)                 |   2021 | ICML   |
|  6 | Expressive 1-Lipschitz Neural Networks for Robust Multiple Graph Learning against Adversarial Attacks                  | ğŸ›¡Defense        | [ğŸ“ICML](http://proceedings.mlr.press/v139/zhao21e.html)                                             |                                                                         |   2021 | ICML   |
|  7 | Robust Graph Representation Learning via Neural Sparsification                                                         | ğŸ›¡Defense        | [ğŸ“ICML](https://proceedings.icml.cc/static/paper_files/icml/2020/2611-Paper.pdf)                    |                                                                         |   2020 | ICML   |
|  8 | Batch Virtual Adversarial Training for Graph Convolutional Networks                                                    | ğŸ›¡Defense        | [ğŸ“ICML](https://arxiv.org/abs/1902.09192)                                                           | [:octocat:Code](https://github.com/thudzj/BVAT)                         |   2019 | ICML   |
|  9 | Latent Adversarial Training of Graph Convolution Networks                                                              | ğŸ›¡Defense        | [ğŸ“LRGSD@ICML](https://graphreason.github.io/papers/35.pdf)                                          | [:octocat:Code](https://github.com/cshjin/LATGCN)                       |   2019 | ICML   |
| 10 | Efficient Robustness Certificates for Discrete Data: Sparsity - Aware Randomized Smoothing for Graphs, Images and More | ğŸ”Certification | [ğŸ“ICML'2020](https://proceedings.icml.cc/book/2020/file/4f7b884f2445ef08da9bbc77b028722c-Paper.pdf) | [:octocat:Code](https://github.com/abojchevski/sparse_smoothing)        |   2020 | ICML   |
# TKDE
|    | Title                                                                                    | Type     | Venue                                      | Code                                                      |   Year | Pubs   |
|---:|:-----------------------------------------------------------------------------------------|:---------|:-------------------------------------------|:----------------------------------------------------------|-------:|:-------|
|  0 | Adversarial Attack on Large Scale Graph                                                  | âš”Attack  | [ğŸ“TKDE](https://arxiv.org/abs/2009.03488) | [:octocat:Code](https://github.com/EdisonLeeeee/SGAttack) |   2021 | TKDE   |
|  1 | NetFense: Adversarial Defenses against Privacy Attacks on Neural Networks for Graph Data | ğŸ›¡Defense | [ğŸ“TKDE](https://arxiv.org/abs/2106.11865) | [:octocat:Code](https://github.com/ICHproject/NetFense)   |   2021 | TKDE   |
|  2 | Graph Adversarial Training: Dynamically Regularizing Based on Graph Structure            | ğŸ›¡Defense | [ğŸ“TKDE](https://arxiv.org/abs/1902.08226) | [:octocat:Code](https://github.com/fulifeng/GraphAT)      |   2019 | TKDE   |
# CIKM
|    | Title                                                                                                                           | Type     | Venue                                                        | Code                                                      |   Year | Pubs   |
|---:|:--------------------------------------------------------------------------------------------------------------------------------|:---------|:-------------------------------------------------------------|:----------------------------------------------------------|-------:|:-------|
|  0 | A Graph Matching Attack on Privacy-Preserving Record Linkage                                                                    | âš”Attack  | [ğŸ“CIKM](https://dl.acm.org/doi/abs/10.1145/3340531.3411931) |                                                           |   2020 | CIKM   |
|  1 | Î±Cyber: Enhancing Robustness of Android Malware Detection System against Adversarial Attacks on Heterogeneous Graph based Model | âš”Attack  | [ğŸ“CIKM](https://dl.acm.org/doi/10.1145/3357384.3357875)     |                                                           |   2019 | CIKM   |
|  2 | A Feature-Importance-Aware and Robust Aggregator for GCN                                                                        | ğŸ›¡Defense | [ğŸ“CIKM](https://dl.acm.org/doi/abs/10.1145/3340531.3411983) | [:octocat:Code](https://github.com/LiZhang-github/LA-GCN) |   2020 | CIKM   |
|  3 | Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters                                             | ğŸ›¡Defense | [ğŸ“CIKM](https://arxiv.org/abs/2008.08692)                   | [:octocat:Code](https://github.com/safe-graph/DGFraud)    |   2020 | CIKM   |
|  4 | Î±Cyber: Enhancing Robustness of Android Malware Detection System against Adversarial Attacks on Heterogeneous Graph based Model | ğŸ›¡Defense | [ğŸ“CIKM](https://dl.acm.org/doi/10.1145/3357384.3357875)     |                                                           |   2019 | CIKM   |
# WSDM
|    | Title                                                                       | Type            | Venue                                                        | Code                                                      |   Year | Pubs   |
|---:|:----------------------------------------------------------------------------|:----------------|:-------------------------------------------------------------|:----------------------------------------------------------|-------:|:-------|
|  0 | Learning to Drop: Robust Graph Neural Network via Topological Denoising     | ğŸ›¡Defense        | [ğŸ“WSDM](https://arxiv.org/abs/2011.07057)                   | [:octocat:Code](https://github.com/flyingdoog/PTDNet)     |   2021 | WSDM   |
|  1 | Node Similarity Preserving Graph Convolutional Networks                     | ğŸ›¡Defense        | [ğŸ“WSDM](https://arxiv.org/abs/2011.09643)                   | [:octocat:Code](https://github.com/ChandlerBang/SimP-GCN) |   2021 | WSDM   |
|  2 | Transferring Robustness for Graph Neural Network Against Poisoning Attacks  | ğŸ›¡Defense        | [ğŸ“WSDM](https://arxiv.org/abs/1908.07558)                   | [:octocat:Code](https://github.com/tangxianfeng/PA-GNN)   |   2020 | WSDM   |
|  3 | All You Need Is Low (Rank): Defending Against Adversarial Attacks on Graphs | ğŸ›¡Defense        | [ğŸ“WSDM](https://dl.acm.org/doi/abs/10.1145/3336191.3371789) | [:octocat:Code](https://github.com/DSE-MSU/DeepRobust)    |   2020 | WSDM   |
|  4 | Adversarial Immunization for Improving Certifiable Robustness on Graphs     | ğŸ”Certification | [ğŸ“WSDM'2021](https://arxiv.org/abs/2007.09647)              |                                                           |   2021 | WSDM   |
# NeurIPS
|    | Title                                                                                                        | Type            | Venue                                                                                            | Code                                                                              |   Year | Pubs    |
|---:|:-------------------------------------------------------------------------------------------------------------|:----------------|:-------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------|-------:|:--------|
|  0 | Adversarial Attacks on Deep Graph Matching                                                                   | âš”Attack         | [ğŸ“NeurIPS](https://papers.nips.cc/paper/2020/file/ef126722e64e98d1c33933783e52eafc-Paper.pdf)   |                                                                                   |   2020 | NeurIPS |
|  1 | Black-Box Adversarial Attacks on Graph Neural Networks with Limited Node Access                              | âš”Attack         | [ğŸ“NeurIPS](https://arxiv.org/abs/2006.05057)                                                    |                                                                                   |   2020 | NeurIPS |
|  2 | Towards More Practical Adversarial Attacks on Graph Neural Networks                                          | âš”Attack         | [ğŸ“NeurIPS](https://arxiv.org/abs/2006.05057)                                                    | [:octocat:Code](https://github.com/Mark12Ding/GNN-Practical-Attack)               |   2020 | NeurIPS |
|  3 | A Unified Framework for Data Poisoning Attack to Graph-based Semi-supervised Learning                        | âš”Attack         | [ğŸ“NeurIPS](https://arxiv.org/abs/1910.14147)                                                    | [:octocat:Code](https://github.com/xuanqing94/AdvSSL)                             |   2019 | NeurIPS |
|  4 | Provable Overlapping Community Detection in Weighted Graphs                                                  | ğŸ›¡Defense        | [ğŸ“NeurIPS](https://arxiv.org/abs/2004.07150)                                                    |                                                                                   |   2020 | NeurIPS |
|  5 | Variational Inference for Graph Convolutional Networks in the Absence of Graph Data and Adversarial Settings | ğŸ›¡Defense        | [ğŸ“NeurIPS](https://arxiv.org/abs/1906.01852)                                                    | [:octocat:Code](https://github.com/ebonilla/VGCN)                                 |   2020 | NeurIPS |
|  6 | Graph Random Neural Networks for Semi-Supervised Learning on Graphs                                          | ğŸ›¡Defense        | [ğŸ“NeurIPS](https://arxiv.org/abs/2005.11079)                                                    | [:octocat:Code](https://github.com/Grand20/grand)                                 |   2020 | NeurIPS |
|  7 | Reliable Graph Neural Networks via Robust Aggregation                                                        | ğŸ›¡Defense        | [ğŸ“NeurIPS](https://arxiv.org/abs/2010.15651)                                                    | [:octocat:Code](https://github.com/sigeisler/reliable_gnn_via_robust_aggregation) |   2020 | NeurIPS |
|  8 | Iterative Deep Graph Learning for Graph Neural Networks: Better and Robust Node Embeddings                   | ğŸ›¡Defense        | [ğŸ“NeurIPS](https://arxiv.org/abs/2006.13009)                                                    | [:octocat:Code](https://github.com/hugochan/IDGL)                                 |   2020 | NeurIPS |
|  9 | Community detection in sparse time-evolving graphs with a dynamical Bethe-Hessian                            | ğŸ›¡Defense        | [ğŸ“NeurIPS](https://arxiv.org/abs/2006.04510)                                                    |                                                                                   |   2020 | NeurIPS |
| 10 | Graph Information Bottleneck                                                                                 | ğŸ›¡Defense        | [ğŸ“NeurIPS](https://arxiv.org/abs/2010.12811)                                                    | [:octocat:Code](http://snap.stanford.edu/gib/)                                    |   2020 | NeurIPS |
| 11 | Graph Contrastive Learning with Augmentations                                                                | ğŸ›¡Defense        | [ğŸ“NeurIPS](https://arxiv.org/abs/2010.13902)                                                    | [:octocat:Code](https://github.com/Shen-Lab/GraphCL)                              |   2020 | NeurIPS |
| 12 | GNNGuard: Defending Graph Neural Networks against Adversarial Attacks                                        | ğŸ›¡Defense        | [ğŸ“NeurIPS](https://arxiv.org/abs/2006.08149)                                                    | [:octocat:Code](https://github.com/mims-harvard/GNNGuard)                         |   2020 | NeurIPS |
| 13 | Certified Robustness of Graph Convolution Networks for Graph Classification under Topological Attacks        | ğŸ”Certification | [ğŸ“NeurIPS'2020](https://www.cs.uic.edu/~zhangx/papers/Jinetal20.pdf)                            | [:octocat:Code](https://github.com/RobustGraph/RoboGraph)                         |   2020 | NeurIPS |
| 14 | Certified Robustness of Graph Classification against Topology Attack with Randomized Smoothing               | ğŸ”Certification | [ğŸ“NeurIPS'2020](https://arxiv.org/abs/2009.05872)                                               |                                                                                   |   2020 | NeurIPS |
| 15 | Certifiable Robustness to Graph Perturbations                                                                | ğŸ”Certification | [ğŸ“NeurIPS'2019](http://papers.nips.cc/paper/9041-certifiable-robustness-to-graph-perturbations) | [:octocat:Code](https://github.com/abojchevski/graph_cert)                        |   2019 | NeurIPS |
| 16 | Graph Robustness Benchmark: Rethinking and Benchmarking Adversarial Robustness of Graph Neural Networks      | âš™Toolbox        | [ğŸ“NeurIPS Openreview â€™2021](https://openreview.net/forum?id=pBwQ82pYha)                         | [**:octocat:Graph Robustness Benchmark (GRB)**](https://github.com/thudm/grb)     |   2021 | NeurIPS |
# USENIX
|    | Title                                                             | Type     | Venue                                                                            | Code   |   Year | Pubs   |
|---:|:------------------------------------------------------------------|:---------|:---------------------------------------------------------------------------------|:-------|-------:|:-------|
|  0 | Stealing Links from Graph Neural Networks                         | âš”Attack  | [ğŸ“USENIX Security](https://www.usenix.org/system/files/sec21summer_he.pdf)      |        |   2021 | USENIX |
|  1 | Graph Backdoor                                                    | âš”Attack  | [ğŸ“USENIX Security](https://arxiv.org/abs/2006.11890)                            |        |   2021 | USENIX |
|  2 | SIGL: Securing Software Installations Through Deep Graph Learning | ğŸš€Others | [ğŸ“USENIX'2021](https://www.usenix.org/system/files/sec21summer_han-xueyuan.pdf) |        |   2021 | USENIX |
# ICDM
|    | Title                                                                   | Type     | Venue                                                                       | Code                                               |   Year | Pubs   |
|---:|:------------------------------------------------------------------------|:---------|:----------------------------------------------------------------------------|:---------------------------------------------------|-------:|:-------|
|  0 | Adversarial Label-Flipping Attack and Defense for Graph Neural Networks | âš”Attack  | [ğŸ“ICDM](http://shichuan.org/doc/97.pdf)                                    | [:octocat:Code](https://github.com/MengmeiZ/LafAK) |   2020 | ICDM   |
|  1 | Exploratory Adversarial Attacks on Graph Neural Networks                | âš”Attack  | [ğŸ“ICDM](https://ieeexplore.ieee.org/document/9338329)                      | [:octocat:Code](https://github.com/EpoAtk/EpoAtk)  |   2020 | ICDM   |
|  2 | AANE: Anomaly Aware Network Embedding For Anomalous Link Detection      | ğŸ›¡Defense | [ğŸ“ICDM](https://ieeexplore.ieee.org/document/9338406)                      |                                                    |   2020 | ICDM   |
|  3 | Provably Robust Node Classification via Low-Pass Message Passing        | ğŸ›¡Defense | [ğŸ“ICDM](https://shenghua-liu.github.io/papers/icdm2020-provablerobust.pdf) |                                                    |   2020 | ICDM   |
|  4 | Adversarial Robustness of Similarity-Based Link Prediction              | ğŸ›¡Defense | [ğŸ“ICDM](https://arxiv.org/abs/1909.01432)                                  |                                                    |   2019 | ICDM   |
# Arxiv
|    | Title                                                                                                               | Type            | Venue                                            | Code                                                                                                             |   Year | Pubs   |
|---:|:--------------------------------------------------------------------------------------------------------------------|:----------------|:-------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------|-------:|:-------|
|  0 | PATHATTACK: Attacking Shortest Paths in Complex Networks                                                            | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2104.03761)      |                                                                                                                  |   2021 | Arxiv  |
|  1 | Optimal Edge Weight Perturbations to Attack Shortest Paths                                                          | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2107.03347)      |                                                                                                                  |   2021 | Arxiv  |
|  2 | Membership Inference Attack on Graph Neural Networks                                                                | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2101.06570)      |                                                                                                                  |   2021 | Arxiv  |
|  3 | BinarizedAttack: Structural Poisoning Attacks to Graph-based Anomaly Detection                                      | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2106.09989)      |                                                                                                                  |   2021 | Arxiv  |
|  4 | Adversarial Attack on Graph Neural Networks as An Influence Maximization Problem                                    | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2106.10785)      |                                                                                                                  |   2021 | Arxiv  |
|  5 | Adversarial Attack Framework on Graph Embedding Models with Limited Knowledge                                       | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2105.12419)      |                                                                                                                  |   2021 | Arxiv  |
|  6 | Black-box Gradient Attack on Graph Neural Networks: Deeper Insights in Graph-based Attack and Defense               | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2104.15061)      |                                                                                                                  |   2021 | Arxiv  |
|  7 | Joint Detection and Localization of Stealth False Data Injection Attacks in Smart Grids using Graph Neural Networks | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2104.11846)      |                                                                                                                  |   2021 | Arxiv  |
|  8 | Adversarial Diffusion Attacks on Graph-based Traffic Prediction Models                                              | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2104.09369)      | [:octocat:Code](https://github.com/LYZ98/Adversarial-Diffusion-Attacks-on-Graph-based-Traffic-Prediction-Models) |   2021 | Arxiv  |
|  9 | Explainability-based Backdoor Attacks Against Graph Neural Networks                                                 | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2104.03674)      |                                                                                                                  |   2021 | Arxiv  |
| 10 | GraphAttacker: A General Multi-Task GraphAttack Framework                                                           | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2101.06855)      |                                                                                                                  |   2021 | Arxiv  |
| 11 | Node-Level Membership Inference Attacks Against Graph Neural Networks                                               | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2102.05429)      |                                                                                                                  |   2021 | Arxiv  |
| 12 | Reinforcement Learning For Data Poisoning on Graph Neural Networks                                                  | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2102.06800)      |                                                                                                                  |   2021 | Arxiv  |
| 13 | Graphfool: Targeted Label Adversarial Attack on Graph Embedding                                                     | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2102.12284)      |                                                                                                                  |   2021 | Arxiv  |
| 14 | Preserve, Promote, or Attack? GNN Explanation via Topology Perturbation                                             | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2103.12256)      |                                                                                                                  |   2021 | Arxiv  |
| 15 | Semantic-preserving Reinforcement Learning Attack Against Graph Neural Networks for Malware Detection               | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2009.05602)      |                                                                                                                  |   2020 | Arxiv  |
| 16 | Scalable Adversarial Attack on Graph Neural Networks with Alternating Direction Method of Multipliers               | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2009.10233)      |                                                                                                                  |   2020 | Arxiv  |
| 17 | Model Extraction Attacks on Graph Neural Networks: Taxonomy and Realization                                         | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2010.12751)      |                                                                                                                  |   2020 | Arxiv  |
| 18 | A Targeted Universal Attack on Graph Convolutional Network                                                          | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2011.14365)      | [:octocat:Code](https://github.com/Nanyuu/TUA)                                                                   |   2020 | Arxiv  |
| 19 | Query-free Black-box Adversarial Attacks on Graphs                                                                  | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2012.06757)      |                                                                                                                  |   2020 | Arxiv  |
| 20 | Reinforcement Learning-based Black-Box Evasion Attacks to Link Prediction in Dynamic Graphs                         | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2009.00163)      |                                                                                                                  |   2020 | Arxiv  |
| 21 | Efficient Evasion Attacks to Graph Neural Networks via Influence Function                                           | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2009.00203)      |                                                                                                                  |   2020 | Arxiv  |
| 22 | Adversarial Attack on Hierarchical Graph Pooling Neural Networks                                                    | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2005.11560)      |                                                                                                                  |   2020 | Arxiv  |
| 23 | MGA: Momentum Gradient Attack on Network                                                                            | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2002.11320)      |                                                                                                                  |   2020 | Arxiv  |
| 24 | Adversarial Attacks to Scale-Free Networks: Testing the Robustness of Physical Criteria                             | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2002.01249)      |                                                                                                                  |   2020 | Arxiv  |
| 25 | Graph Universal Adversarial Attacks: A Few Bad Actors Ruin Graph Learning Models                                    | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2002.04784)      | [:octocat:Code](https://github.com/chisam0217/Graph-Universal-Attack)                                            |   2020 | Arxiv  |
| 26 | Adversarial Perturbations of Opinion Dynamics in Networks                                                           | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2003.07010)      |                                                                                                                  |   2020 | Arxiv  |
| 27 | Network disruption: maximizing disagreement and polarization in social networks                                     | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/2003.08377)      | [:octocat:Code](https://github.com/mayee107/network-disruption)                                                  |   2020 | Arxiv  |
| 28 | Time-aware Gradient Attack on Dynamic Network Link Prediction                                                       | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/1911.10561)      |                                                                                                                  |   2019 | Arxiv  |
| 29 | Attacking Graph Convolutional Networks via Rewiring                                                                 | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/1906.03750)      |                                                                                                                  |   2019 | Arxiv  |
| 30 | Unsupervised Euclidean Distance Attack on Network Embedding                                                         | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/1905.11015)      |                                                                                                                  |   2019 | Arxiv  |
| 31 | Generalizable Adversarial Attacks with Latent Variable Perturbation Modelling                                       | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/1905.10864)      |                                                                                                                  |   2019 | Arxiv  |
| 32 | Vertex Nomination, Consistent Estimation, and Adversarial Modification                                              | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/1905.01776)      |                                                                                                                  |   2019 | Arxiv  |
| 33 | Multiscale Evolutionary Perturbation Attack on Community Detection                                                  | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/1910.09741)      |                                                                                                                  |   2019 | Arxiv  |
| 34 | Fake Node Attacks on Graph Convolutional Networks                                                                   | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/1810.10751)      |                                                                                                                  |   2018 | Arxiv  |
| 35 | Data Poisoning Attack against Unsupervised Node Embedding Methods                                                   | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/1810.12881)      |                                                                                                                  |   2018 | Arxiv  |
| 36 | Fast Gradient Attack on Network Embedding                                                                           | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/1809.02797)      |                                                                                                                  |   2018 | Arxiv  |
| 37 | Attack Tolerance of Link Prediction Algorithms: How to Hide Your Relations in a Social Network                      | âš”Attack         | [ğŸ“Arxiv](https://arxiv.org/abs/1809.00152)      |                                                                                                                  |   2018 | Arxiv  |
| 38 | How effective are Graph Neural Networks in Fraud Detection for Network Data?                                        | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2105.14568)      |                                                                                                                  |   2021 | Arxiv  |
| 39 | Graph Sanitation with Application to Node Classification                                                            | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2105.09384)      |                                                                                                                  |   2021 | Arxiv  |
| 40 | A Robust and Generalized Framework for Adversarial Graph Embedding                                                  | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2105.10651)      | [:octocat:Code](https://github.com/RingBDStack/AGE)                                                              |   2021 | Arxiv  |
| 41 | Adversarial Graph Augmentation to Improve Graph Contrastive Learning                                                | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2106.05819)      |                                                                                                                  |   2021 | Arxiv  |
| 42 | Improving Robustness of Graph Neural Networks with Heterophily-Inspired Designs                                     | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2106.07767)      |                                                                                                                  |   2021 | Arxiv  |
| 43 | Robust Counterfactual Explanations on Graph Neural Networks                                                         | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2107.04086)      |                                                                                                                  |   2021 | Arxiv  |
| 44 | Robust Graph Learning Under Wasserstein Uncertainty                                                                 | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2105.04210)      |                                                                                                                  |   2021 | Arxiv  |
| 45 | Towards Robust Graph Contrastive Learning                                                                           | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2102.13085)      |                                                                                                                  |   2021 | Arxiv  |
| 46 | Interpretable Stability Bounds for Spectral Graph Filters                                                           | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2102.09587)      |                                                                                                                  |   2021 | Arxiv  |
| 47 | Unified Robust Training for Graph NeuralNetworks against Label Noise                                                | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2103.03414)      |                                                                                                                  |   2021 | Arxiv  |
| 48 | An Introduction to Robust Graph Convolutional Networks                                                              | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2103.14807)      |                                                                                                                  |   2021 | Arxiv  |
| 49 | E-GraphSAGE: A Graph Neural Network based Intrusion Detection System                                                | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2103.16329)      |                                                                                                                  |   2021 | Arxiv  |
| 50 | Spatio-Temporal Sparsification for General Robust Graph Convolution Networks                                        | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2103.12256)      |                                                                                                                  |   2021 | Arxiv  |
| 51 | Node Copying for Protection Against Graph Neural Network Topology Attacks                                           | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2007.06704)      |                                                                                                                  |   2020 | Arxiv  |
| 52 | Unsupervised Adversarially-Robust Representation Learning on Graphs                                                 | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2012.02486)      |                                                                                                                  |   2020 | Arxiv  |
| 53 | Anti-perturbation of Online Social Networks by Graph Label Transition                                               | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2010.14121)      |                                                                                                                  |   2020 | Arxiv  |
| 54 | I-GCN: Robust Graph Convolutional Network via Influence Mechanism                                                   | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2012.06110)      |                                                                                                                  |   2020 | Arxiv  |
| 55 | RoGAT: a robust GNN combined revised GAT with adjusted graphs                                                       | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2009.13038)      |                                                                                                                  |   2020 | Arxiv  |
| 56 | ResGCN: Attention-based Deep Residual Modeling for Anomaly Detection on Attributed Networks                         | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2009.14738)      |                                                                                                                  |   2020 | Arxiv  |
| 57 | Adversarial Perturbations of Opinion Dynamics in Networks                                                           | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2003.07010)      |                                                                                                                  |   2020 | Arxiv  |
| 58 | Adversarial Privacy Preserving Graph Embedding against Inference Attack                                             | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2008.13072)      | [:octocat:Code](https://github.com/uJ62JHD/Privacy-Preserving-Social-Network-Embedding)                          |   2020 | Arxiv  |
| 59 | Evaluating Graph Vulnerability and Robustness using TIGER                                                           | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2006.05648)      |                                                                                                                  |   2020 | Arxiv  |
| 60 | Topological Effects on Attacks Against Vertex Classification                                                        | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2003.05822)      |                                                                                                                  |   2020 | Arxiv  |
| 61 | Tensor Graph Convolutional Networks for Multi-relational and Robust Learning                                        | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2003.07729)      |                                                                                                                  |   2020 | Arxiv  |
| 62 | DefenseVGAE: Defending against Adversarial Attacks on Graph Data via a Variational Graph Autoencoder                | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2006.08900)      | [:octocat:Code](https://github.com/zhangao520/defense-vgae)                                                      |   2020 | Arxiv  |
| 63 | Dynamic Knowledge Graph-based Dialogue Generation with Improved Adversarial Meta-Learning                           | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/2004.08833)      |                                                                                                                  |   2020 | Arxiv  |
| 64 | Target Defense Against Link-Prediction-Based Attacks via Evolutionary Perturbations                                 | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/1809.05912)      |                                                                                                                  |   2019 | Arxiv  |
| 65 | Examining Adversarial Learning against Graph-based IoT Malware Detection Systems                                    | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/1902.04416)      |                                                                                                                  |   2019 | Arxiv  |
| 66 | Adversarial Embedding: A robust and elusive Steganography and Watermarking technique                                | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/1912.01487)      |                                                                                                                  |   2019 | Arxiv  |
| 67 | Graph Interpolating Activation Improves Both Natural and Robust Accuracies in Data-Efficient Deep Learning          | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/1907.06800)      | [:octocat:Code](https://github.com/BaoWangMath/DNN-DataDependentActivation)                                      |   2019 | Arxiv  |
| 68 | Adversarial Defense Framework for Graph Neural Network                                                              | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/1905.03679)      |                                                                                                                  |   2019 | Arxiv  |
| 69 | GraphSAC: Detecting anomalies in large-scale graphs                                                                 | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/1910.09589)      |                                                                                                                  |   2019 | Arxiv  |
| 70 | Edge Dithering for Robust Adaptive Graph Convolutional Networks                                                     | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/1910.09590)      |                                                                                                                  |   2019 | Arxiv  |
| 71 | Can Adversarial Network Attack be Defended?                                                                         | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/1903.05994)      |                                                                                                                  |   2019 | Arxiv  |
| 72 | GraphDefense: Towards Robust Graph Convolutional Networks                                                           | ğŸ›¡Defense        | [ğŸ“Arxiv](https://arxiv.org/abs/1911.04429)      |                                                                                                                  |   2019 | Arxiv  |
| 73 | Certified Robustness of Graph Neural Networks against Adversarial Structural Perturbation                           | ğŸ”Certification | [ğŸ“Arxiv'2020](https://arxiv.org/abs/2008.10715) |                                                                                                                  |   2020 | Arxiv  |
| 74 | Stability of Graph Convolutional Neural Networks to Stochastic Perturbations                                        | âš–Stability      | [ğŸ“Arxiv'2021](https://arxiv.org/abs/2106.10526) |                                                                                                                  |   2021 | Arxiv  |
| 75 | Graph and Graphon Neural Network Stability                                                                          | âš–Stability      | [ğŸ“Arxiv'2020](https://arxiv.org/abs/2008.01767) |                                                                                                                  |   2020 | Arxiv  |
| 76 | On the Stability of Graph Convolutional Neural Networks under Edge Rewiring                                         | âš–Stability      | [ğŸ“Arxiv'2020](https://arxiv.org/abs/2010.13747) |                                                                                                                  |   2020 | Arxiv  |
| 77 | Graph Neural Networks: Architectures, Stability and Transferability                                                 | âš–Stability      | [ğŸ“Arxiv'2020](https://arxiv.org/abs/2008.01767) |                                                                                                                  |   2020 | Arxiv  |
| 78 | Should Graph Convolution Trust Neighbors? A Simple Causal Inference Method                                          | âš–Stability      | [ğŸ“Arxiv'2020](https://arxiv.org/abs/2010.11797) |                                                                                                                  |   2020 | Arxiv  |
| 79 | Stability Properties of Graph Neural Networks                                                                       | âš–Stability      | [ğŸ“Arxiv'2019](https://arxiv.org/abs/1905.04497) |                                                                                                                  |   2019 | Arxiv  |
| 80 | FLAG: Adversarial Data Augmentation for Graph Neural Networks                                                       | ğŸš€Others        | [ğŸ“Arxiv'2020](https://arxiv.org/abs/2010.09891) | [:octocat:Code](https://github.com/devnkong/FLAG)                                                                |   2020 | Arxiv  |
| 81 | Dynamic Knowledge Graph-based Dialogue Generation with Improved Adversarial Meta-Learning                           | ğŸš€Others        | [ğŸ“Arxiv'2020](https://arxiv.org/abs/2004.08833) |                                                                                                                  |   2020 | Arxiv  |
| 82 | Watermarking Graph Neural Networks by Random Graphs                                                                 | ğŸš€Others        | [ğŸ“Arxiv'2020](https://arxiv.org/abs/2011.00512) |                                                                                                                  |   2020 | Arxiv  |
| 83 | Graph Neural Networks Taxonomy, Advances and Trends                                                                 | ğŸ“ƒSurvey        | [ğŸ“Arxiv'2020](https://arxiv.org/abs/2012.08752) |                                                                                                                  |   2020 | Arxiv  |
| 84 | A Survey of Adversarial Learning on Graph                                                                           | ğŸ“ƒSurvey        | [ğŸ“Arxiv'2020](https://arxiv.org/abs/2003.05730) |                                                                                                                  |   2020 | Arxiv  |
| 85 | Adversarial Attacks and Defenses on Graphs: A Review and Empirical Study                                            | ğŸ“ƒSurvey        | [ğŸ“Arxiv'2020](https://arxiv.org/abs/2003.00653) |                                                                                                                  |   2020 | Arxiv  |
| 86 | Adversarial Attacks and Defenses in Images, Graphs and Text: A Review                                               | ğŸ“ƒSurvey        | [ğŸ“Arxiv'2019](https://arxiv.org/abs/1909.08072) |                                                                                                                  |   2019 | Arxiv  |
| 87 | Adversarial Attack and Defense on Graph Data: A Survey                                                              | ğŸ“ƒSurvey        | [ğŸ“Arxiv'2018](https://arxiv.org/abs/1812.10528) |                                                                                                                  |   2018 | Arxiv  |
| 88 | Deep Learning on Graphs A Survey                                                                                    | ğŸ“ƒSurvey        | [ğŸ“Arxiv'2018](https://arxiv.org/abs/1812.04202) |                                                                                                                  |   2018 | Arxiv  |
| 89 | Evaluating Graph Vulnerability and Robustness using TIGER                                                           | âš™Toolbox        | [ğŸ“Arxivâ€˜2021](https://arxiv.org/abs/2006.05648) | [**:octocat:TIGER**](https://github.com/safreita1/TIGER)                                                         |   2021 | Arxiv  |
# UAI
|    | Title                                                      | Type     | Venue                                          | Code                                                    |   Year | Pubs   |
|---:|:-----------------------------------------------------------|:---------|:-----------------------------------------------|:--------------------------------------------------------|-------:|:-------|
|  0 | Adversarial Sets for Regularising Neural Link Predictors   | âš”Attack  | [ğŸ“UAI](https://arxiv.org/abs/1707.07596)      | [:octocat:Code](https://github.com/uclmr/inferbeddings) |   2017 | UAI    |
|  1 | Adversarial Sets for Regularising Neural Link Predictors   | ğŸ›¡Defense | [ğŸ“UAI](https://arxiv.org/abs/1707.07596)      | [:octocat:Code](https://github.com/uclmr/inferbeddings) |   2017 | UAI    |
|  2 | Generating Adversarial Examples with Graph Neural Networks | ğŸš€Others | [ğŸ“UAI'2021](https://arxiv.org/abs/2105.14644) |                                                         |   2021 | UAI    |
# ICSE
|    | Title                                                                                                                   | Type     | Venue                                                                     | Code                                                                      |   Year | Pubs   |
|---:|:------------------------------------------------------------------------------------------------------------------------|:---------|:--------------------------------------------------------------------------|:--------------------------------------------------------------------------|-------:|:-------|
|  0 | GraphGallery: A Platform for Fast Benchmarking and Easy Development of Graph Neural Networks Based Intelligent Software | âš™Toolbox | [ğŸ“ICSE Demoâ€˜2021](https://ieeexplore.ieee.org/abstract/document/9402641) | [**:octocat:GraphGallery**](https://github.com/EdisonLeeeee/GraphGallery) |   2021 | ICSE   |
# ECAI
|    | Title                                                                                   | Type            | Venue                                                 | Code   |   Year | Pubs   |
|---:|:----------------------------------------------------------------------------------------|:----------------|:------------------------------------------------------|:-------|-------:|:-------|
|  0 | Abstract Interpretation based Robustness Certification for Graph Convolutional Networks | ğŸ”Certification | [ğŸ“ECAI'2020](http://ecai2020.eu/papers/31_paper.pdf) |        |   2020 | ECAI   |
# Others
|    | Title                                                                                                    | Type            | Venue                                                                                                                                                                         | Code                                                                            |   Year | Pubs   |
|---:|:---------------------------------------------------------------------------------------------------------|:----------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------|-------:|:-------|
|  0 | Structack: Structure-based Adversarial Attacks on Graph Neural Networks                                  | âš”Attack         | [ğŸ“ACM Hypertext](https://arxiv.org/abs/2107.11327)                                                                                                                           | [:octocat:Code](https://github.com/sqrhussain/structack)                        |   2021 | Others |
|  1 | GReady for Emerging Threats to Recommender Systems? A Graph Convolution-based Generative Shilling Attack | âš”Attack         | [ğŸ“Information Sciences](https://arxiv.org/abs/2107.10457)                                                                                                                    |                                                                                 |   2021 | Others |
|  2 | Universal Spectral Adversarial Attacks for Deformable Shapes                                             | âš”Attack         | [ğŸ“CVPR](https://arxiv.org/abs/2104.03356)                                                                                                                                    |                                                                                 |   2021 | Others |
|  3 | Towards Revealing Parallel Adversarial Attack on Politician Socialnet of Graph Structure                 | âš”Attack         | [ğŸ“Security and Communication Networks](https://www.hindawi.com/journals/scn/2021/6631247)                                                                                    |                                                                                 |   2021 | Others |
|  4 | Network Embedding Attack: An Euclidean Distance Based Method                                             | âš”Attack         | [ğŸ“MDATA](https://link.springer.com/chapter/10.1007%2F978-3-030-71590-8_8)                                                                                                    |                                                                                 |   2021 | Others |
|  5 | Adaptive Adversarial Attack on Graph Embedding via GAN                                                   | âš”Attack         | [ğŸ“SocialSec](https://link.springer.com/chapter/10.1007/978-981-15-9031-3_7)                                                                                                  |                                                                                 |   2020 | Others |
|  6 | Attacking Graph-Based Classification without Changing Existing Connections                               | âš”Attack         | [ğŸ“ACSAC](https://cse.sc.edu/~zeng1/papers/2020-acsac-graph.pdf)                                                                                                              |                                                                                 |   2020 | Others |
|  7 | Cross Entropy Attack on Deep Graph Infomax                                                               | âš”Attack         | [ğŸ“IEEE ISCAS](https://ieeexplore.ieee.org/document/9180817)                                                                                                                  |                                                                                 |   2020 | Others |
|  8 | Link Prediction Adversarial Attack Via Iterative Gradient Attack                                         | âš”Attack         | [ğŸ“IEEE Trans](https://ieeexplore.ieee.org/abstract/document/9141291)                                                                                                         |                                                                                 |   2020 | Others |
|  9 | Manipulating Node Similarity Measures in Networks                                                        | âš”Attack         | [ğŸ“AAMAS](https://arxiv.org/abs/1910.11529)                                                                                                                                   |                                                                                 |   2020 | Others |
| 10 | Indirect Adversarial Attacks via Poisoning Neighbors for Graph Convolutional Networks                    | âš”Attack         | [ğŸ“BigData](https://arxiv.org/abs/2002.08012)                                                                                                                                 |                                                                                 |   2020 | Others |
| 11 | Adversarial Attacks on Link Prediction Algorithms Based on Graph Neural Networks                         | âš”Attack         | [ğŸ“Asia CCS](https://iqua.ece.toronto.edu/papers/wlin-asiaccs20.pdf)                                                                                                          |                                                                                 |   2020 | Others |
| 12 | Adversarial attack on BC classification for scale-free networks                                          | âš”Attack         | [ğŸ“AIP Chaos](https://aip.scitation.org/doi/10.1063/5.0003707)                                                                                                                |                                                                                 |   2020 | Others |
| 13 | Network Structural Vulnerability A Multi-Objective Attacker Perspective                                  | âš”Attack         | [ğŸ“IEEE Trans](https://ieeexplore.ieee.org/document/8275029)                                                                                                                  |                                                                                 |   2019 | Others |
| 14 | GA Based Q-Attack on Community Detection                                                                 | âš”Attack         | [ğŸ“TCSS](https://arxiv.org/abs/1811.00430)                                                                                                                                    |                                                                                 |   2019 | Others |
| 15 | Attacking Graph-based Classification via Manipulating the Graph Structure                                | âš”Attack         | [ğŸ“CCS](https://arxiv.org/abs/1903.00553)                                                                                                                                     |                                                                                 |   2019 | Others |
| 16 | Hiding Individuals and Communities in a Social Network                                                   | âš”Attack         | [ğŸ“Nature Human Behavior](https://arxiv.org/abs/1608.00375)                                                                                                                   |                                                                                 |   2018 | Others |
| 17 | Attacking Similarity-Based Link Prediction in Social Networks                                            | âš”Attack         | [ğŸ“AAMAS](https://arxiv.org/abs/1809.08368)                                                                                                                                   |                                                                                 |   2018 | Others |
| 18 | Practical Attacks Against Graph-based Clustering                                                         | âš”Attack         | [ğŸ“CCS](https://arxiv.org/abs/1708.09056)                                                                                                                                     |                                                                                 |   2017 | Others |
| 19 | Unveiling Anomalous Nodes Via Random Sampling and Consensus on Graphs                                    | ğŸ›¡Defense        | [ğŸ“ICASSP](https://ieeexplore.ieee.org/abstract/document/9414953)                                                                                                             |                                                                                 |   2021 | Others |
| 20 | On Generalization of Graph Autoencoders with Adversarial Training                                        | ğŸ›¡Defense        | [ğŸ“ECML](https://arxiv.org/abs/2107.02658)                                                                                                                                    |                                                                                 |   2021 | Others |
| 21 | DeepInsight: Interpretability Assisting Detection of Adversarial Samples on Graphs                       | ğŸ›¡Defense        | [ğŸ“ECML](https://arxiv.org/abs/2106.09501)                                                                                                                                    |                                                                                 |   2021 | Others |
| 22 | Enhancing Robustness and Resilience of Multiplex Networks Against Node-Community Cascading Failures      | ğŸ›¡Defense        | [ğŸ“IEEE TSMC](https://ieeexplore.ieee.org/abstract/document/9415463)                                                                                                          |                                                                                 |   2021 | Others |
| 23 | Robust graph convolutional networks with directional graph adversarial training                          | ğŸ›¡Defense        | [ğŸ“Applied Intelligence](https://link.springer.com/article/10.1007/s10489-021-02272-y)                                                                                        |                                                                                 |   2021 | Others |
| 24 | Detection and Defense of Topological Adversarial Attacks on Graphs                                       | ğŸ›¡Defense        | [ğŸ“AISTATS](http://proceedings.mlr.press/v130/zhang21i.html)                                                                                                                  |                                                                                 |   2021 | Others |
| 25 | A Novel Defending Scheme for Graph-Based Classification Against Graph Structure Manipulating Attack      | ğŸ›¡Defense        | [ğŸ“SocialSec](https://link.springer.com/chapter/10.1007/978-981-15-9031-3_26)                                                                                                 |                                                                                 |   2020 | Others |
| 26 | Adversarial Detection on Graph Structured Data                                                           | ğŸ›¡Defense        | [ğŸ“PPMLP](https://dl.acm.org/doi/abs/10.1145/3411501.3419424)                                                                                                                 |                                                                                 |   2020 | Others |
| 27 | Learning Graph Embedding with Adversarial Training Methods                                               | ğŸ›¡Defense        | [ğŸ“IEEE Transactions on Cybernetics](https://arxiv.org/abs/1901.01250)                                                                                                        |                                                                                 |   2020 | Others |
| 28 | Smoothing Adversarial Training for GNN                                                                   | ğŸ›¡Defense        | [ğŸ“IEEE TCSS](https://ieeexplore.ieee.org/abstract/document/9305289?casa_token=fTXIL3hT1yIAAAAA:I4fn-GlF0PIwzPRC87SayRi5_pi2ZDDuSancEsY96A4O4bUBEsp0hSYMNJVGVzMgBWxycYN9qu6D) |                                                                                 |   2020 | Others |
| 29 | Graph Structure Reshaping Against Adversarial Attacks on Graph Neural Networks                           | ğŸ›¡Defense        | [ğŸ“None](None)                                                                                                                                                                | [:octocat:Code](https://github.com/GraphReshape/GraphReshape)                   |   2020 | Others |
| 30 | Robust Graph Learning From Noisy Data                                                                    | ğŸ›¡Defense        | [ğŸ“IEEE Trans](https://ieeexplore.ieee.org/abstract/document/8605364)                                                                                                         |                                                                                 |   2020 | Others |
| 31 | How Robust Are Graph Neural Networks to Structural Noise?                                                | ğŸ›¡Defense        | [ğŸ“DLGMA](https://arxiv.org/abs/1912.10206)                                                                                                                                   |                                                                                 |   2020 | Others |
| 32 | On The Stability of Polynomial Spectral Graph Filters                                                    | ğŸ›¡Defense        | [ğŸ“ICASSP](https://ieeexplore.ieee.org/abstract/document/9054072)                                                                                                             | [:octocat:Code](https://github.com/henrykenlay/spgf)                            |   2020 | Others |
| 33 | Towards an Efficient and General Framework of Robust Training for Graph Neural Networks                  | ğŸ›¡Defense        | [ğŸ“ICASSP](https://arxiv.org/abs/2002.10947)                                                                                                                                  |                                                                                 |   2020 | Others |
| 34 | Robust Collective Classification against Structural Attacks                                              | ğŸ›¡Defense        | [ğŸ“Preprint](http://www.auai.org/uai2020/proceedings/119_main_paper.pdf)                                                                                                      |                                                                                 |   2020 | Others |
| 35 | Virtual Adversarial Training on Graph Convolutional Networks in Node Classification                      | ğŸ›¡Defense        | [ğŸ“PRCV](https://arxiv.org/abs/1902.11045)                                                                                                                                    |                                                                                 |   2019 | Others |
| 36 | Investigating Robustness and Interpretability of Link Prediction via Adversarial Modifications           | ğŸ›¡Defense        | [ğŸ“NAACL](https://arxiv.org/abs/1905.00563)                                                                                                                                   | [:octocat:Code](https://github.com/pouyapez/criage)                             |   2019 | Others |
| 37 | Adversarial Personalized Ranking for Recommendation                                                      | ğŸ›¡Defense        | [ğŸ“SIGIR](https://dl.acm.org/citation.cfm?id=3209981)                                                                                                                         | [:octocat:Code](https://github.com/hexiangnan/adversarial_personalized_ranking) |   2018 | Others |
| 38 | Robust Certification for Laplace Learning on Geometric Graphs                                            | ğŸ”Certification | [ğŸ“MSMLâ€™2021](https://arxiv.org/abs/2104.10837)                                                                                                                               |                                                                                 |   2021 | Others |
| 39 | Stability of Graph Neural Networks to Relative Perturbations                                             | âš–Stability      | [ğŸ“ICASSP'2020](https://ieeexplore.ieee.org/document/9054341)                                                                                                                 |                                                                                 |   2020 | Others |
| 40 | Perturbation Sensitivity of GNNs                                                                         | ğŸš€Others        | [ğŸ“cs224w'2019](http://snap.stanford.edu/class/cs224w-2019/project/26424139.pdf)                                                                                              |                                                                                 |   2019 | Others |
