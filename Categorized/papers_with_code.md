|     | Title                                                                                                                  | Type            | Venue                                                                                                | Code                                                                                                             |   Year |
|----:|:-----------------------------------------------------------------------------------------------------------------------|:----------------|:-----------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------|-------:|
|   0 | Adversarial Attack on Graph Neural Networks as An Influence Maximization Problem                                       | ⚔Attack         | [📝WSDM](https://arxiv.org/abs/2106.10785)                                                           | [:octocat:Code](https://github.com/TheaperDeng/GNN-Attack-InfMax)                                                |   2022 |
|   1 | Inference Attacks Against Graph Neural Networks                                                                        | ⚔Attack         | [📝USENIX Security](https://arxiv.org/abs/2110.02631)                                                | [:octocat:Code](https://github.com/Zhangzhk0819/GNN-Embedding-Leaks)                                             |   2022 |
|   2 | Model Stealing Attacks Against Inductive Graph Neural Networks                                                         | ⚔Attack         | [📝IEEE Symposium on Security and Privacy](https://arxiv.org/abs/2112.08331)                         | [:octocat:Code](https://github.com/xinleihe/GNNStealing)                                                         |   2022 |
|   3 | Unsupervised Graph Poisoning Attack via Contrastive Loss Back-propagation                                              | ⚔Attack         | [📝WWW](https://arxiv.org/abs/2201.07986)                                                            | [:octocat:Code](https://github.com/RinneSz/CLGA)                                                                 |   2022 |
|   4 | Neighboring Backdoor Attacks on Graph Convolutional Network                                                            | ⚔Attack         | [📝arXiv](https://arxiv.org/abs/2201.06202)                                                          | [:octocat:Code](https://github.com/EdisonLeeeee/GraphWar)                                                        |   2022 |
|   5 | Understanding and Improving Graph Injection Attack by Promoting Unnoticeability                                        | ⚔Attack         | [📝ICLR](https://openreview.net/forum?id=wkMG8cdvh7-)                                                | [:octocat:Code](https://openreview.net/attachment?id=wkMG8cdvh7-&name=supplementary_material)                    |   2022 |
|   6 | Blindfolded Attackers Still Threatening: Strict Black-Box Adversarial Attacks on Graphs                                | ⚔Attack         | [📝AAAI](https://arxiv.org/abs/2012.06757)                                                           | [:octocat:Code](https://github.com/galina0217/stack)                                                             |   2022 |
|   7 | Black-box Node Injection Attack for Graph Neural Networks                                                              | ⚔Attack         | [📝arXiv](https://arxiv.org/abs/2202.09389)                                                          | [:octocat:Code](https://github.com/jumxglhf/GA2C)                                                                |   2022 |
|   8 | Model Extraction Attacks on Graph Neural Networks: Taxonomy and Realization                                            | ⚔Attack         | [📝Asia CCS](https://arxiv.org/abs/2010.12751)                                                       | [:octocat:Code](https://github.com/TrustworthyGNN/MEA-GNN)                                                       |   2022 |
|   9 | Structack: Structure-based Adversarial Attacks on Graph Neural Networks                                                | ⚔Attack         | [📝ACM Hypertext](https://arxiv.org/abs/2107.11327)                                                  | [:octocat:Code](https://github.com/sqrhussain/structack)                                                         |   2021 |
|  10 | Graph Adversarial Attack via Rewiring                                                                                  | ⚔Attack         | [📝KDD](https://dl.acm.org/doi/abs/10.1145/3447548.3467416)                                          | [:octocat:Code](https://github.com/alge24/ReWatt)                                                                |   2021 |
|  11 | TDGIA: Effective Injection Attacks on Graph Neural Networks                                                            | ⚔Attack         | [📝KDD](https://dl.acm.org/doi/abs/10.1145/3447548.3467314)                                          | [:octocat:Code](https://github.com/THUDM/tdgia)                                                                  |   2021 |
|  12 | Adversarial Attack on Large Scale Graph                                                                                | ⚔Attack         | [📝TKDE](https://arxiv.org/abs/2009.03488)                                                           | [:octocat:Code](https://github.com/EdisonLeeeee/SGAttack)                                                        |   2021 |
|  13 | SAGE: Intrusion Alert-driven Attack Graph Extractor                                                                    | ⚔Attack         | [📝KDD Workshop](https://arxiv.org/abs/2107.02783)                                                   | [:octocat:Code](https://github.com/tudelft-cda-lab/SAGE)                                                         |   2021 |
|  14 | Adversarial Diffusion Attacks on Graph-based Traffic Prediction Models                                                 | ⚔Attack         | [📝arXiv](https://arxiv.org/abs/2104.09369)                                                          | [:octocat:Code](https://github.com/LYZ98/Adversarial-Diffusion-Attacks-on-Graph-based-Traffic-Prediction-Models) |   2021 |
|  15 | VIKING: Adversarial Attack on Network Embeddings via Supervised Network Poisoning                                      | ⚔Attack         | [📝PAKDD](https://arxiv.org/abs/2102.07164)                                                          | [:octocat:Code](https://github.com/virresh/viking)                                                               |   2021 |
|  16 | GraphAttacker: A General Multi-Task GraphAttack Framework                                                              | ⚔Attack         | [📝arXiv](https://arxiv.org/abs/2101.06855)                                                          | [:octocat:Code](https://github.com/honoluluuuu/GraphAttacker)                                                    |   2021 |
|  17 | Graph Stochastic Neural Networks for Semi-supervised Learning                                                          | ⚔Attack         | [📝arXiv](https://papers.nips.cc/paper/2020/file/e586a4f55fb43a540c2e9dab45e00f53-Paper.pdf)         | [:octocat:Code](https://github.com/GSNN/GSNN)                                                                    |   2021 |
|  18 | Iterative Deep Graph Learning for Graph Neural Networks: Better and Robust Node Embeddings                             | ⚔Attack         | [📝arXiv](https://arxiv.org/abs/2006.13009)                                                          | [:octocat:Code](https://github.com/hugochan/IDGL)                                                                |   2021 |
|  19 | Single-Node Attack for Fooling Graph Neural Networks                                                                   | ⚔Attack         | [📝KDD Workshop](https://drive.google.com/file/d/12arm9w6UmvSIzGmaoocdH70czx7RVzGr/view)             | [:octocat:Code](https://github.com/gnnattack/SINGLE)                                                             |   2021 |
|  20 | Poisoning Knowledge Graph Embeddings via Relation Inference Patterns                                                   | ⚔Attack         | [📝ACL](https://aclanthology.org/2021.acl-long.147)                                                  | [:octocat:Code](https://github.com/PeruBhardwaj/InferenceAttack)                                                 |   2021 |
|  21 | Single Node Injection Attack against Graph Neural Networks                                                             | ⚔Attack         | [📝CIKM](https://arxiv.org/abs/2108.13049)                                                           | [:octocat:Code](https://github.com/TaoShuchang/G-NIA)                                                            |   2021 |
|  22 | Adapting Membership Inference Attacks to GNN for Graph Classification: Approaches and Implications                     | ⚔Attack         | [📝ICDM](https://arxiv.org/abs/2110.08760)                                                           | [:octocat:Code](https://github.com/TrustworthyGNN/MIA-GNN)                                                       |   2021 |
|  23 | Robustness of Graph Neural Networks at Scale                                                                           | ⚔Attack         | [📝NeurIPS](https://arxiv.org/pdf/2110.14038.pdf)                                                    | [:octocat:Code](https://github.com/sigeisler/robustness_of_gnns_at_scale)                                        |   2021 |
|  24 | Graph Universal Adversarial Attacks: A Few Bad Actors Ruin Graph Learning Models                                       | ⚔Attack         | [📝IJCAI](https://www.ijcai.org/proceedings/2021/458)                                                | [:octocat:Code](https://github.com/chisam0217/Graph-Universal-Attack)                                            |   2021 |
|  25 | Adversarial Attacks on Graph Classification via Bayesian Optimisation                                                  | ⚔Attack         | [📝NeurIPS](https://arxiv.org/abs/2111.02842)                                                        | [:octocat:Code](https://github.com/xingchenwan/grabnel)                                                          |   2021 |
|  26 | Adversarial Attacks on Knowledge Graph Embeddings via Instance Attribution Methods                                     | ⚔Attack         | [📝EMNLP](https://arxiv.org/abs/2111.03120)                                                          | [:octocat:Code](https://github.com/PeruBhardwaj/AttributionAttack)                                               |   2021 |
|  27 | UNTANGLE: Unlocking Routing and Logic Obfuscation Using Graph Neural Networks-based Link Prediction                    | ⚔Attack         | [📝ICCAD](https://arxiv.org/abs/2111.07062)                                                          | [:octocat:Code](https://github.com/lilasrahis/untangle)                                                          |   2021 |
|  28 | GraphMI: Extracting Private Graph Data from Graph Neural Networks                                                      | ⚔Attack         | [📝IJCAI](https://www.ijcai.org/proceedings/2021/516)                                                | [:octocat:Code](https://github.com/zaixizhang/GraphMI)                                                           |   2021 |
|  29 | Learning to Deceive Knowledge Graph Augmented Models via Targeted Perturbation                                         | ⚔Attack         | [📝ICLR](https://arxiv.org/abs/2010.12872)                                                           | [:octocat:Code](https://github.com/INK-USC/deceive-KG-models)                                                    |   2020 |
|  30 | Towards More Practical Adversarial Attacks on Graph Neural Networks                                                    | ⚔Attack         | [📝NeurIPS](https://arxiv.org/abs/2006.05057)                                                        | [:octocat:Code](https://github.com/Mark12Ding/GNN-Practical-Attack)                                              |   2020 |
|  31 | Adversarial Label-Flipping Attack and Defense for Graph Neural Networks                                                | ⚔Attack         | [📝ICDM](http://shichuan.org/doc/97.pdf)                                                             | [:octocat:Code](https://github.com/MengmeiZ/LafAK)                                                               |   2020 |
|  32 | Exploratory Adversarial Attacks on Graph Neural Networks                                                               | ⚔Attack         | [📝ICDM](https://ieeexplore.ieee.org/document/9338329)                                               | [:octocat:Code](https://github.com/EpoAtk/EpoAtk)                                                                |   2020 |
|  33 | A Targeted Universal Attack on Graph Convolutional Network                                                             | ⚔Attack         | [📝arXiv](https://arxiv.org/abs/2011.14365)                                                          | [:octocat:Code](https://github.com/Nanyuu/TUA)                                                                   |   2020 |
|  34 | Backdoor Attacks to Graph Neural Networks                                                                              | ⚔Attack         | [📝SACMAT](https://dl.acm.org/doi/pdf/10.1145/3450569.3463560)                                       | [:octocat:Code](https://github.com/zaixizhang/graphbackdoor)                                                     |   2020 |
|  35 | Adversarial Attack on Community Detection by Hiding Individuals                                                        | ⚔Attack         | [📝WWW](https://arxiv.org/abs/2001.07933)                                                            | [:octocat:Code](https://github.com/halimiqi/CD-ATTACK)                                                           |   2020 |
|  36 | A Restricted Black-box Adversarial Framework Towards Attacking Graph Embedding Models                                  | ⚔Attack         | [📝AAAI](https://arxiv.org/abs/1908.01297)                                                           | [:octocat:Code](https://github.com/SwiftieH/GFAttack)                                                            |   2020 |
|  37 | Scalable Attack on Graph Data by Injecting Vicious Nodes                                                               | ⚔Attack         | [📝ECML-PKDD](https://arxiv.org/abs/2004.13825)                                                      | [:octocat:Code](https://github.com/wangjh-github/AFGSM)                                                          |   2020 |
|  38 | Network disruption: maximizing disagreement and polarization in social networks                                        | ⚔Attack         | [📝arXiv](https://arxiv.org/abs/2003.08377)                                                          | [:octocat:Code](https://github.com/mayee107/network-disruption)                                                  |   2020 |
|  39 | Structured Adversarial Attack Towards General Implementation and Better Interpretability                               | ⚔Attack         | [📝ICLR](https://arxiv.org/abs/1808.01664)                                                           | [:octocat:Code](https://github.com/KaidiXu/StrAttack)                                                            |   2019 |
|  40 | PeerNets Exploiting Peer Wisdom Against Adversarial Attacks                                                            | ⚔Attack         | [📝ICLR](https://arxiv.org/abs/1806.00088)                                                           | [:octocat:Code](https://github.com/tantara/PeerNets-pytorch)                                                     |   2019 |
|  41 | Adversarial Attacks on Node Embeddings via Graph Poisoning                                                             | ⚔Attack         | [📝ICML](https://arxiv.org/abs/1809.01093)                                                           | [:octocat:Code](https://github.com/abojchevski/node_embedding_attack)                                            |   2019 |
|  42 | Adversarial Attacks on Graph Neural Networks via Meta Learning                                                         | ⚔Attack         | [📝ICLR](https://arxiv.org/abs/1902.08412)                                                           | [:octocat:Code](https://github.com/danielzuegner/gnn-meta-attack)                                                |   2019 |
|  43 | Topology Attack and Defense for Graph Neural Networks: An Optimization Perspective                                     | ⚔Attack         | [📝IJCAI](https://arxiv.org/abs/1906.04214)                                                          | [:octocat:Code](https://github.com/KaidiXu/GCN_ADV_Train)                                                        |   2019 |
|  44 | Adversarial Examples on Graph Data: Deep Insights into Attack and Defense                                              | ⚔Attack         | [📝IJCAI](https://arxiv.org/abs/1903.01610)                                                          | [:octocat:Code](https://github.com/stellargraph/stellargraph/tree/develop/demos/interpretability)                |   2019 |
|  45 | A Unified Framework for Data Poisoning Attack to Graph-based Semi-supervised Learning                                  | ⚔Attack         | [📝NeurIPS](https://arxiv.org/abs/1910.14147)                                                        | [:octocat:Code](https://github.com/xuanqing94/AdvSSL)                                                            |   2019 |
|  46 | Adversarial Attacks on Neural Networks for Graph Data                                                                  | ⚔Attack         | [📝KDD](https://arxiv.org/abs/1805.07984)                                                            | [:octocat:Code](https://github.com/danielzuegner/nettack)                                                        |   2018 |
|  47 | Adversarial Attack on Graph Structured Data                                                                            | ⚔Attack         | [📝ICML](https://arxiv.org/abs/1806.02371)                                                           | [:octocat:Code](https://github.com/Hanjun-Dai/graph_adversarial_attack)                                          |   2018 |
|  48 | Adversarial Sets for Regularising Neural Link Predictors                                                               | ⚔Attack         | [📝UAI](https://arxiv.org/abs/1707.07596)                                                            | [:octocat:Code](https://github.com/uclmr/inferbeddings)                                                          |   2017 |
|  49 | Unsupervised Adversarially-Robust Representation Learning on Graphs                                                    | 🛡Defense        | [📝AAAI](https://arxiv.org/abs/2012.02486)                                                           | [:octocat:Code](https://github.com/galina0217/robustgraph)                                                       |   2022 |
|  50 | Towards Robust Graph Neural Networks for Noisy Graphs with Sparse Labels                                               | 🛡Defense        | [📝arXiv](https://arxiv.org/abs/2201.00232)                                                          | [:octocat:Code](https://github.com/EnyanDai/RSGNN)                                                               |   2022 |
|  51 | Mind Your Solver! On Adversarial Attack and Defense for Combinatorial Optimization                                     | 🛡Defense        | [📝arXiv](https://arxiv.org/abs/2201.004022)                                                         | [:octocat:Code](https://github.com/EnyanDai/RSGNN)                                                               |   2022 |
|  52 | Graph Neural Network for Local Corruption Recovery                                                                     | 🛡Defense        | [📝arXiv](https://arxiv.org/abs/2202.04936)                                                          | [:octocat:Code](https://github.com/bzho3923/MAGnet)                                                              |   2022 |
|  53 | Defending Graph Convolutional Networks against Dynamic Graph Perturbations via Bayesian Self-supervision               | 🛡Defense        | [📝AAAI](https://arxiv.org/abs/2203.03762)                                                           | [:octocat:Code](https://github.com/junzhuang-code/GraphSS)                                                       |   2022 |
|  54 | SimGRACE: A Simple Framework for Graph Contrastive Learning without Data Augmentation                                  | 🛡Defense        | [📝WWW](https://arxiv.org/abs/2202.03104)                                                            | [:octocat:Code](https://github.com/junxia97/SimGRACE)                                                            |   2022 |
|  55 | Learning to Drop: Robust Graph Neural Network via Topological Denoising                                                | 🛡Defense        | [📝WSDM](https://arxiv.org/abs/2011.07057)                                                           | [:octocat:Code](https://github.com/flyingdoog/PTDNet)                                                            |   2021 |
|  56 | Understanding Structural Vulnerability in Graph Convolutional Networks                                                 | 🛡Defense        | [📝IJCAI](https://www.ijcai.org/proceedings/2021/310)                                                | [:octocat:Code](https://github.com/EdisonLeeeee/MedianGCN)                                                       |   2021 |
|  57 | A Robust and Generalized Framework for Adversarial Graph Embedding                                                     | 🛡Defense        | [📝arXiv](https://arxiv.org/abs/2105.10651)                                                          | [:octocat:Code](https://github.com/RingBDStack/AGE)                                                              |   2021 |
|  58 | Information Obfuscation of Graph Neural Network                                                                        | 🛡Defense        | [📝ICML](https://arxiv.org/pdf/2009.13504.pdf)                                                       | [:octocat:Code](https://github.com/liaopeiyuan/GAL)                                                              |   2021 |
|  59 | Elastic Graph Neural Networks                                                                                          | 🛡Defense        | [📝ICML](http://proceedings.mlr.press/v139/liu21k/liu21k.pdf)                                        | [:octocat:Code](https://github.com/lxiaorui/ElasticGNN)                                                          |   2021 |
|  60 | Node Similarity Preserving Graph Convolutional Networks                                                                | 🛡Defense        | [📝WSDM](https://arxiv.org/abs/2011.09643)                                                           | [:octocat:Code](https://github.com/ChandlerBang/SimP-GCN)                                                        |   2021 |
|  61 | NetFense: Adversarial Defenses against Privacy Attacks on Neural Networks for Graph Data                               | 🛡Defense        | [📝TKDE](https://arxiv.org/abs/2106.11865)                                                           | [:octocat:Code](https://github.com/ICHproject/NetFense)                                                          |   2021 |
|  62 | Power up! Robust Graph Convolutional Network against Evasion Attacks based on Graph Powering                           | 🛡Defense        | [📝AAAI](https://arxiv.org/abs/1905.10029)                                                           | [:octocat:Code](https://www.dropbox.com/sh/p36pzx1ock2iamo/AABEr7FtM5nqwC4i9nICLIsta?dl=0)                       |   2021 |
|  63 | Unveiling the potential of Graph Neural Networks for robust Intrusion Detection                                        | 🛡Defense        | [📝arXiv](https://arxiv.org/abs/2107.14747)                                                          | [:octocat:Code](https://github.com/BNN-UPC/GNN-NIDS)                                                             |   2021 |
|  64 | A Lightweight Metric Defence Strategy for Graph Neural Networks Against Poisoning Attacks                              | 🛡Defense        | [📝ICICS](https://link.springer.com/chapter/10.1007/978-3-030-88052-1_4)                             | [:octocat:Code](https://github.com/lizi-learner/MD-GNN)                                                          |   2021 |
|  65 | Node Feature Kernels Increase Graph Convolutional Network Robustness                                                   | 🛡Defense        | [📝arXiv](https://arxiv.org/abs/2109.01785)                                                          | [:octocat:Code](https://github.com/ChangminWu/RobustGCN)                                                         |   2021 |
|  66 | Not All Low-Pass Filters are Robust in Graph Convolutional Networks                                                    | 🛡Defense        | [📝NeurIPS](https://openreview.net/forum?id=bDdfxLQITtu)                                             | [:octocat:Code](https://github.com/SwiftieH/LFR)                                                                 |   2021 |
|  67 | Graph Neural Networks with Adaptive Residual                                                                           | 🛡Defense        | [NeurIPS](https://openreview.net/forum?id=hfkER_KJiNw)                                               | [:octocat:Code](https://github.com/lxiaorui/AirGNN)                                                              |   2021 |
|  68 | Graph Posterior Network: Bayesian Predictive Uncertainty for Node Classification                                       | 🛡Defense        | [📝NeurIPS](https://arxiv.org/pdf/2110.14012.pdf)                                                    | [:octocat:Code](https://github.com/stadlmax/Graph-Posterior-Network)                                             |   2021 |
|  69 | Variational Inference for Graph Convolutional Networks in the Absence of Graph Data and Adversarial Settings           | 🛡Defense        | [📝NeurIPS](https://arxiv.org/abs/1906.01852)                                                        | [:octocat:Code](https://github.com/ebonilla/VGCN)                                                                |   2020 |
|  70 | Graph Random Neural Networks for Semi-Supervised Learning on Graphs                                                    | 🛡Defense        | [📝NeurIPS](https://arxiv.org/abs/2005.11079)                                                        | [:octocat:Code](https://github.com/Grand20/grand)                                                                |   2020 |
|  71 | Reliable Graph Neural Networks via Robust Aggregation                                                                  | 🛡Defense        | [📝NeurIPS](https://arxiv.org/abs/2010.15651)                                                        | [:octocat:Code](https://github.com/sigeisler/reliable_gnn_via_robust_aggregation)                                |   2020 |
|  72 | Graph Adversarial Networks: Protecting Information against Adversarial Attacks                                         | 🛡Defense        | [📝ICLR OpenReview](https://openreview.net/forum?id=Q8ZdJahesWe)                                     | [:octocat:Code](https://github.com/liaopeiyuan/GAL)                                                              |   2020 |
|  73 | A Feature-Importance-Aware and Robust Aggregator for GCN                                                               | 🛡Defense        | [📝CIKM](https://dl.acm.org/doi/abs/10.1145/3340531.3411983)                                         | [:octocat:Code](https://github.com/LiZhang-github/LA-GCN)                                                        |   2020 |
|  74 | Graph Information Bottleneck                                                                                           | 🛡Defense        | [📝NeurIPS](https://arxiv.org/abs/2010.12811)                                                        | [:octocat:Code](http://snap.stanford.edu/gib/)                                                                   |   2020 |
|  75 | Graph Contrastive Learning with Augmentations                                                                          | 🛡Defense        | [📝NeurIPS](https://arxiv.org/abs/2010.13902)                                                        | [:octocat:Code](https://github.com/Shen-Lab/GraphCL)                                                             |   2020 |
|  76 | Graph Structure Reshaping Against Adversarial Attacks on Graph Neural Networks                                         | 🛡Defense        | [📝None](None)                                                                                       | [:octocat:Code](https://github.com/GraphReshape/GraphReshape)                                                    |   2020 |
|  77 | Adversarial Privacy Preserving Graph Embedding against Inference Attack                                                | 🛡Defense        | [📝arXiv](https://arxiv.org/abs/2008.13072)                                                          | [:octocat:Code](https://github.com/uJ62JHD/Privacy-Preserving-Social-Network-Embedding)                          |   2020 |
|  78 | GNNGuard: Defending Graph Neural Networks against Adversarial Attacks                                                  | 🛡Defense        | [📝NeurIPS](https://arxiv.org/abs/2006.08149)                                                        | [:octocat:Code](https://github.com/mims-harvard/GNNGuard)                                                        |   2020 |
|  79 | Transferring Robustness for Graph Neural Network Against Poisoning Attacks                                             | 🛡Defense        | [📝WSDM](https://arxiv.org/abs/1908.07558)                                                           | [:octocat:Code](https://github.com/tangxianfeng/PA-GNN)                                                          |   2020 |
|  80 | All You Need Is Low (Rank): Defending Against Adversarial Attacks on Graphs                                            | 🛡Defense        | [📝WSDM](https://dl.acm.org/doi/abs/10.1145/3336191.3371789)                                         | [:octocat:Code](https://github.com/DSE-MSU/DeepRobust)                                                           |   2020 |
|  81 | Robust Detection of Adaptive Spammers by Nash Reinforcement Learning                                                   | 🛡Defense        | [📝KDD](https://arxiv.org/abs/2006.06069)                                                            | [:octocat:Code](https://github.com/YingtongDou/Nash-Detect)                                                      |   2020 |
|  82 | Graph Structure Learning for Robust Graph Neural Networks                                                              | 🛡Defense        | [📝KDD](https://arxiv.org/abs/2005.10203)                                                            | [:octocat:Code](https://github.com/DSE-MSU/DeepRobust)                                                           |   2020 |
|  83 | On The Stability of Polynomial Spectral Graph Filters                                                                  | 🛡Defense        | [📝ICASSP](https://ieeexplore.ieee.org/abstract/document/9054072)                                    | [:octocat:Code](https://github.com/henrykenlay/spgf)                                                             |   2020 |
|  84 | On the Robustness of Cascade Diffusion under Node Attacks                                                              | 🛡Defense        | [📝WWW](https://www.cs.au.dk/~karras/robustIC.pdf)                                                   | [:octocat:Code](https://github.com/allogn/robustness)                                                            |   2020 |
|  85 | Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters                                    | 🛡Defense        | [📝CIKM](https://arxiv.org/abs/2008.08692)                                                           | [:octocat:Code](https://github.com/safe-graph/DGFraud)                                                           |   2020 |
|  86 | DefenseVGAE: Defending against Adversarial Attacks on Graph Data via a Variational Graph Autoencoder                   | 🛡Defense        | [📝arXiv](https://arxiv.org/abs/2006.08900)                                                          | [:octocat:Code](https://github.com/zhangao520/defense-vgae)                                                      |   2020 |
|  87 | Graph-Revised Convolutional Network                                                                                    | 🛡Defense        | [📝ECML-PKDD](https://arxiv.org/abs/1911.07123)                                                      | [:octocat:Code](https://github.com/PlusRoss/GRCN)                                                                |   2020 |
|  88 | Graph Adversarial Training: Dynamically Regularizing Based on Graph Structure                                          | 🛡Defense        | [📝TKDE](https://arxiv.org/abs/1902.08226)                                                           | [:octocat:Code](https://github.com/fulifeng/GraphAT)                                                             |   2019 |
|  89 | Bayesian graph convolutional neural networks for semi-supervised classification                                        | 🛡Defense        | [📝AAAI](https://arxiv.org/abs/1811.11103)                                                           | [:octocat:Code](https://github.com/huawei-noah/BGCN)                                                             |   2019 |
|  90 | Graph Interpolating Activation Improves Both Natural and Robust Accuracies in Data-Efficient Deep Learning             | 🛡Defense        | [📝arXiv](https://arxiv.org/abs/1907.06800)                                                          | [:octocat:Code](https://github.com/BaoWangMath/DNN-DataDependentActivation)                                      |   2019 |
|  91 | Adversarial Training Methods for Network Embedding                                                                     | 🛡Defense        | [📝WWW](https://arxiv.org/abs/1908.11514)                                                            | [:octocat:Code](https://github.com/wonniu/AdvT4NE_WWW2019)                                                       |   2019 |
|  92 | Batch Virtual Adversarial Training for Graph Convolutional Networks                                                    | 🛡Defense        | [📝ICML](https://arxiv.org/abs/1902.09192)                                                           | [:octocat:Code](https://github.com/thudzj/BVAT)                                                                  |   2019 |
|  93 | Latent Adversarial Training of Graph Convolution Networks                                                              | 🛡Defense        | [📝LRGSD@ICML](https://graphreason.github.io/papers/35.pdf)                                          | [:octocat:Code](https://github.com/cshjin/LATGCN)                                                                |   2019 |
|  94 | Characterizing Malicious Edges targeting on Graph Neural Networks                                                      | 🛡Defense        | [📝ICLR OpenReview](https://arxiv.org/abs/1906.04214)                                                | [:octocat:Code](https://github.com/KaidiXu/GCN_ADV_Train)                                                        |   2019 |
|  95 | Robust Graph Convolutional Networks Against Adversarial Attacks                                                        | 🛡Defense        | [📝KDD](http://pengcui.thumedialab.com/papers/RGCN.pdf)                                              | [:octocat:Code](https://github.com/thumanlab/nrlweb/blob/master/static/assets/download/RGCN.zip)                 |   2019 |
|  96 | Investigating Robustness and Interpretability of Link Prediction via Adversarial Modifications                         | 🛡Defense        | [📝NAACL](https://arxiv.org/abs/1905.00563)                                                          | [:octocat:Code](https://github.com/pouyapez/criage)                                                              |   2019 |
|  97 | Adversarial Personalized Ranking for Recommendation                                                                    | 🛡Defense        | [📝SIGIR](https://dl.acm.org/citation.cfm?id=3209981)                                                | [:octocat:Code](https://github.com/hexiangnan/adversarial_personalized_ranking)                                  |   2018 |
|  98 | Certified Robustness of Graph Neural Networks against Adversarial Structural Perturbation                              | 🔐Certification | [📝KDD'2021](https://dl.acm.org/doi/abs/10.1145/3447548.3467295)                                     | [:octocat:Code](https://github.com/binghuiwang/CertifyGNN)                                                       |   2021 |
|  99 | Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks                                | 🔐Certification | [📝ICLR'2021](https://openreview.net/forum?id=ULQdiUTHe3y)                                           | [:octocat:Code](https://github.com/jan-schuchardt/collective_robustness)                                         |   2021 |
| 100 | Certified Robustness of Graph Convolution Networks for Graph Classification under Topological Attacks                  | 🔐Certification | [📝NeurIPS'2020](https://www.cs.uic.edu/~zhangx/papers/Jinetal20.pdf)                                | [:octocat:Code](https://github.com/RobustGraph/RoboGraph)                                                        |   2020 |
| 101 | Efficient Robustness Certificates for Discrete Data: Sparsity - Aware Randomized Smoothing for Graphs, Images and More | 🔐Certification | [📝ICML'2020](https://proceedings.icml.cc/book/2020/file/4f7b884f2445ef08da9bbc77b028722c-Paper.pdf) | [:octocat:Code](https://github.com/abojchevski/sparse_smoothing)                                                 |   2020 |
| 102 | Certifiable Robustness of Graph Convolutional Networks under Structure Perturbation                                    | 🔐Certification | [📝KDD'2020](https://dl.acm.org/doi/10.1145/3394486.3403217)                                         | [:octocat:Code](https://github.com/danielzuegner/robust-gcn-structure)                                           |   2020 |
| 103 | Certifiable Robustness and Robust Training for Graph Convolutional Networks                                            | 🔐Certification | [📝KDD'2019](https://arxiv.org/abs/1906.12269)                                                       | [:octocat:Code](https://www.kdd.in.tum.de/research/robust-gcn/)                                                  |   2019 |
| 104 | Certifiable Robustness to Graph Perturbations                                                                          | 🔐Certification | [📝NeurIPS'2019](http://papers.nips.cc/paper/9041-certifiable-robustness-to-graph-perturbations)     | [:octocat:Code](https://github.com/abojchevski/graph_cert)                                                       |   2019 |
| 105 | When Do GNNs Work: Understanding and Improving Neighborhood Aggregation                                                | ⚖Stability      | [📝IJCAI Workshop'2019](https://www.ijcai.org/Proceedings/2020/181)                                  | [:octocat:Code](https://github.com/raspberryice/ala-gcn)                                                         |   2019 |
| 106 | Towards a Unified Framework for Fair and Stable Graph Representation Learning                                          | ⚖Stability      | [📝UAI'2021](https://arxiv.org/abs/2102.13186)                                                       | [:octocat:Code](https://github.com/chirag126/nifty)                                                              |   2021 |
| 107 | FLAG: Adversarial Data Augmentation for Graph Neural Networks                                                          | 🚀Others        | [📝arXiv'2020](https://arxiv.org/abs/2010.09891)                                                     | [:octocat:Code](https://github.com/devnkong/FLAG)                                                                |   2020 |
| 108 | Training Robust Graph Neural Network by Applying Lipschitz Constant Constraint                                         | 🚀Others        | [📝CentraleSupélec'2020](https://github.com/SJTUzhou/Lipschitz_gnn/blob/main/GNN_Robust_report.pdf)  | [:octocat:Code](https://github.com/SJTUzhou/Lipschitz_gnn)                                                       |   2020 |
| 109 | DeepRobust: a Platform for Adversarial Attacks and Defenses                                                            | ⚙Toolbox        | [📝AAAI’2021](https://ojs.aaai.org/index.php/AAAI/article/view/18017)                                | [**:octocat:DeepRobust**](https://github.com/DSE-MSU/DeepRobust)                                                 |   2021 |
| 110 | GraphWar: A graph adversarial learning toolbox based on PyTorch and DGL                                                | ⚙Toolbox        | [📝arXiv’2022]()                                                                                     | [**:octocat:GraphWar**](https://github.com/EdisonLeeeee/GraphWar)                                                |   2022 |
| 111 | Evaluating Graph Vulnerability and Robustness using TIGER                                                              | ⚙Toolbox        | [📝arXiv‘2021](https://arxiv.org/abs/2006.05648)                                                     | [**:octocat:TIGER**](https://github.com/safreita1/TIGER)                                                         |   2021 |
| 112 | Graph Robustness Benchmark: Rethinking and Benchmarking Adversarial Robustness of Graph Neural Networks                | ⚙Toolbox        | [📝NeurIPS Openreview’2021](https://openreview.net/forum?id=pBwQ82pYha)                              | [**:octocat:Graph Robustness Benchmark (GRB)**](https://github.com/thudm/grb)                                    |   2021 |