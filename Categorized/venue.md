# AAAI
|    | Title                                                                                                | Type            | Venue                                                                                                                      | Code                                                                                       |   Year |
|---:|:-----------------------------------------------------------------------------------------------------|:----------------|:---------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------|-------:|
|  0 | Attacking Graph Neural Networks at Scale                                                             | ⚔Attack         | [📝AAAI workshop](https://www.dropbox.com/s/ddrwoswpz3wwx40/Robust_GNNs_at_Scale__AAAI_Workshop_2020_CameraReady.pdf?dl=0) |                                                                                            |   2021 |
|  1 | DeHiB: Deep Hidden Backdoor Attack on Semi-Supervised Learning via Adversarial Perturbation          | ⚔Attack         | [📝AAAI](https://ojs.aaai.org/index.php/AAAI/article/view/17266)                                                           |                                                                                            |   2021 |
|  2 | A Restricted Black-box Adversarial Framework Towards Attacking Graph Embedding Models                | ⚔Attack         | [📝AAAI](https://arxiv.org/abs/1908.01297)                                                                                 | [:octocat:Code](https://github.com/SwiftieH/GFAttack)                                      |   2020 |
|  3 | UAG: Uncertainty-Aware Attention Graph Neural Network for Defending Adversarial Attacks              | 🛡Defense        | [📝AAAI](https://arxiv.org/abs/2009.10235)                                                                                 |                                                                                            |   2021 |
|  4 | Uncertainty-Matching Graph Neural Networks to Defend Against Poisoning Attacks                       | 🛡Defense        | [📝AAAI](https://arxiv.org/abs/2009.14455)                                                                                 |                                                                                            |   2021 |
|  5 | Power up! Robust Graph Convolutional Network against Evasion Attacks based on Graph Powering         | 🛡Defense        | [📝AAAI](https://arxiv.org/abs/1905.10029)                                                                                 | [:octocat:Code](https://www.dropbox.com/sh/p36pzx1ock2iamo/AABEr7FtM5nqwC4i9nICLIsta?dl=0) |   2021 |
|  6 | Personalized privacy protection in social networks through adversarial modeling                      | 🛡Defense        | [📝AAAI](https://www.cs.uic.edu/~elena/pubs/biradar-ppai21.pdf)                                                            |                                                                                            |   2021 |
|  7 | Randomized Generation of Adversary-Aware Fake Knowledge Graphs to Combat Intellectual Property Theft | 🛡Defense        | [📝AAAI](http://34.94.61.102/paper_AAAI-9475.html)                                                                         |                                                                                            |   2021 |
|  8 | Adversary for Social Good: Protecting Familial Privacy through Joint Adversarial Attacks             | 🛡Defense        | [📝AAAI](https://ojs.aaai.org//index.php/AAAI/article/view/6791)                                                           |                                                                                            |   2020 |
|  9 | Bayesian graph convolutional neural networks for semi-supervised classification                      | 🛡Defense        | [📝AAAI](https://arxiv.org/abs/1811.11103)                                                                                 | [:octocat:Code](https://github.com/huawei-noah/BGCN)                                       |   2019 |
| 10 | Improving the Robustness of Wasserstein Embedding by Adversarial PAC-Bayesian Learning               | 🔐Certification | [📝AAAI'2020](http://staff.ustc.edu.cn/~hexn/papers/aaai20-adversarial-embedding.pdf)                                      |                                                                                            |   2020 |
| 11 | DeepRobust: a Platform for Adversarial Attacks and Defenses                                          | ⚙Toolbox        | [📝AAAI’2021](https://ojs.aaai.org/index.php/AAAI/article/view/18017)                                                      | [**:octocat:DeepRobust**](https://github.com/DSE-MSU/DeepRobust)                           |   2021 |
# IJCAI
|    | Title                                                                              | Type       | Venue                                                               | Code                                                                                              |   Year |
|---:|:-----------------------------------------------------------------------------------|:-----------|:--------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------|-------:|
|  0 | An Efficient Adversarial Attack on Graph Structured Data                           | ⚔Attack    | [📝IJCAI Workshop](https://www.aisafetyw.org/programme)             |                                                                                                   |   2020 |
|  1 | An Efficient Adversarial Attack on Graph Structured Data                           | ⚔Attack    | [📝IJCAI Workshop](https://www.aisafetyw.org/programme)             |                                                                                                   |   2020 |
|  2 | Data Poisoning Attack against Knowledge Graph Embedding                            | ⚔Attack    | [📝IJCAI](https://arxiv.org/abs/1904.12052)                         |                                                                                                   |   2019 |
|  3 | Topology Attack and Defense for Graph Neural Networks: An Optimization Perspective | ⚔Attack    | [📝IJCAI](https://arxiv.org/abs/1906.04214)                         | [:octocat:Code](https://github.com/KaidiXu/GCN_ADV_Train)                                         |   2019 |
|  4 | Adversarial Examples on Graph Data: Deep Insights into Attack and Defense          | ⚔Attack    | [📝IJCAI](https://arxiv.org/abs/1903.01610)                         | [:octocat:Code](https://github.com/stellargraph/stellargraph/tree/develop/demos/interpretability) |   2019 |
|  5 | Understanding Structural Vulnerability in Graph Convolutional Networks             | 🛡Defense   | [📝IJCAI](https://arxiv.org/abs/2108.06280)                         | [:octocat:Code](https://github.com/EdisonLeeeee/MedianGCN)                                        |   2021 |
|  6 | Adversarial Examples on Graph Data: Deep Insights into Attack and Defense          | 🛡Defense   | [📝IJCAI](https://arxiv.org/abs/1903.01610)                         | [:octocat:Code](https://github.com/DSE-MSU/DeepRobust)                                            |   2019 |
|  7 | Topology Attack and Defense for Graph Neural Networks: An Optimization Perspective | 🛡Defense   | [📝IJCAI](https://arxiv.org/abs/1906.04214)                         | [:octocat:Code](https://github.com/KaidiXu/GCN_ADV_Train)                                         |   2019 |
|  8 | When Do GNNs Work: Understanding and Improving Neighborhood Aggregation            | ⚖Stability | [📝IJCAI Workshop'2019](https://www.ijcai.org/Proceedings/2020/181) | [:octocat:Code](https://github.com/raspberryice/ala-gcn)                                          |   2019 |
|  9 | Deep Graph Structure Learning for Robust Representations: A Survey                 | 📃Survey   | [📝IJCAI Survey track'2021](https://arxiv.org/abs/2103.03036)       |                                                                                                   |   2021 |
# ICLR
|    | Title                                                                                       | Type            | Venue                                                                 | Code                                                              |   Year |
|---:|:--------------------------------------------------------------------------------------------|:----------------|:----------------------------------------------------------------------|:------------------------------------------------------------------|-------:|
|  0 | One Vertex Attack on Graph Neural Networks-based Spatiotemporal Forecasting                 | ⚔Attack         | [📝ICLR OpenReview](https://openreview.net/forum?id=W0MKrbVOxtd)      |                                                                   |   2020 |
|  1 | Single-Node Attack for Fooling Graph Neural Networks                                        | ⚔Attack         | [📝ICLR OpenReview](https://openreview.net/forum?id=u4WfreuXxnk)      | [:octocat:Code](https://github.com/benfinkelshtein/SINGLE)        |   2020 |
|  2 | Black-Box Adversarial Attacks on Graph Neural Networks as An Influence Maximization Problem | ⚔Attack         | [📝ICLR OpenReview](https://openreview.net/forum?id=sbyjwhxxT8K)      |                                                                   |   2020 |
|  3 | Learning to Deceive Knowledge Graph Augmented Models via Targeted Perturbation              | ⚔Attack         | [📝ICLR](https://arxiv.org/abs/2010.12872)                            | [:octocat:Code](https://github.com/INK-USC/deceive-KG-models)     |   2020 |
|  4 | Backdoor Attacks to Graph Neural Networks                                                   | ⚔Attack         | [📝ICLR OpenReview](https://arxiv.org/abs/2006.11165)                 |                                                                   |   2020 |
|  5 | Structured Adversarial Attack Towards General Implementation and Better Interpretability    | ⚔Attack         | [📝ICLR](https://arxiv.org/abs/1808.01664)                            | [:octocat:Code](https://github.com/KaidiXu/StrAttack)             |   2019 |
|  6 | PeerNets Exploiting Peer Wisdom Against Adversarial Attacks                                 | ⚔Attack         | [📝ICLR](https://arxiv.org/abs/1806.00088)                            | [:octocat:Code](https://github.com/tantara/PeerNets-pytorch)      |   2019 |
|  7 | Adversarial Attacks on Graph Neural Networks via Meta Learning                              | ⚔Attack         | [📝ICLR](https://arxiv.org/abs/1902.08412)                            | [:octocat:Code](https://github.com/danielzuegner/gnn-meta-attack) |   2019 |
|  8 | Ricci-GNN: Defending Against Structural Attacks Through a Geometric Approach                | 🛡Defense        | [📝ICLR OpenReview](https://openreview.net/forum?id=_qoQkWNEhS)       |                                                                   |   2020 |
|  9 | Towards Robust Graph Neural Networks against Label Noise                                    | 🛡Defense        | [📝ICLR OpenReview](https://openreview.net/forum?id=H38f_9b90BO)      |                                                                   |   2020 |
| 10 | Graph Adversarial Networks: Protecting Information against Adversarial Attacks              | 🛡Defense        | [📝ICLR OpenReview](https://openreview.net/forum?id=Q8ZdJahesWe)      | [:octocat:Code](https://github.com/liaopeiyuan/GAL)               |   2020 |
| 11 | Characterizing Malicious Edges targeting on Graph Neural Networks                           | 🛡Defense        | [📝ICLR OpenReview](https://arxiv.org/abs/1906.04214)                 | [:octocat:Code](https://github.com/KaidiXu/GCN_ADV_Train)         |   2019 |
| 12 | Comparing and Detecting Adversarial Attacks for Graph Deep Learning                         | 🛡Defense        | [📝RLGM@ICLR](https://rlgm.github.io/papers/57.pdf)                   |                                                                   |   2019 |
| 13 | Collective Robustness Certificates                                                          | 🔐Certification | [📝ICLR'2021](https://openreview.net/forum?id=ULQdiUTHe3y)            |                                                                   |   2021 |
| 14 | Certifying Robustness of Graph Laplacian Based Semi-Supervised Learning                     | 🔐Certification | [📝ICLR OpenReview'2021](https://openreview.net/forum?id=cQyybLUoXxc) |                                                                   |   2021 |
# WWW
|    | Title                                                                                                               | Type            | Venue                                                         | Code                                                       |   Year |
|---:|:--------------------------------------------------------------------------------------------------------------------|:----------------|:--------------------------------------------------------------|:-----------------------------------------------------------|-------:|
|  0 | Adversarial Attack on Community Detection by Hiding Individuals                                                     | ⚔Attack         | [📝WWW](https://arxiv.org/abs/2001.07933)                     | [:octocat:Code](https://github.com/halimiqi/CD-ATTACK)     |   2020 |
|  1 | Non-target-specific Node Injection Attacks on Graph Neural Networks: A Hierarchical Reinforcement Learning Approach | ⚔Attack         | [📝WWW](http://faculty.ist.psu.edu/vhonavar/Papers/www20.pdf) |                                                            |   2020 |
|  2 | Robust Network Alignment via Attack Signal Scaling and Adversarial Perturbation Elimination                         | 🛡Defense        | [📝WWW](http://eng.auburn.edu/users/yangzhou/papers/RNA.pdf)  |                                                            |   2021 |
|  3 | On the Robustness of Cascade Diffusion under Node Attacks                                                           | 🛡Defense        | [📝WWW](https://www.cs.au.dk/~karras/robustIC.pdf)            | [:octocat:Code](https://github.com/allogn/robustness)      |   2020 |
|  4 | Friend or Faux: Graph-Based Early Detection of Fake Accounts on Social Networks                                     | 🛡Defense        | [📝WWW](https://arxiv.org/abs/2004.04834)                     |                                                            |   2020 |
|  5 | Adversarial Training Methods for Network Embedding                                                                  | 🛡Defense        | [📝WWW](https://arxiv.org/abs/1908.11514)                     | [:octocat:Code](https://github.com/wonniu/AdvT4NE_WWW2019) |   2019 |
|  6 | Certified Robustness of Community Detection against Adversarial Structural Perturbation via Randomized Smoothing    | 🔐Certification | [📝WWW'2020](https://arxiv.org/abs/2002.03421)                |                                                            |   2020 |
# KDD
|    | Title                                                                                     | Type            | Venue                                                             | Code                                                                                             |   Year |
|---:|:------------------------------------------------------------------------------------------|:----------------|:------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------|-------:|
|  0 | Graph Adversarial Attack via Rewiring                                                     | ⚔Attack         | [📝KDD](https://dl.acm.org/doi/abs/10.1145/3447548.3467416)       | [:octocat:Code](https://github.com/alge24/ReWatt)                                                |   2021 |
|  1 | TDGIA: Effective Injection Attacks on Graph Neural Networks                               | ⚔Attack         | [📝KDD](https://dl.acm.org/doi/abs/10.1145/3447548.3467314)       | [:octocat:Code](https://github.com/THUDM/tdgia)                                                  |   2021 |
|  2 | SAGE: Intrusion Alert-driven Attack Graph Extractor                                       | ⚔Attack         | [📝KDD Workshop](https://arxiv.org/abs/2107.02783)                | [:octocat:Code](https://github.com/tudelft-cda-lab/SAGE)                                         |   2021 |
|  3 | VIKING: Adversarial Attack on Network Embeddings via Supervised Network Poisoning         | ⚔Attack         | [📝PAKDD](https://arxiv.org/abs/2102.07164)                       | [:octocat:Code](https://github.com/virresh/viking)                                               |   2021 |
|  4 | Adversarial Attacks on Graph Neural Networks: Perturbations and their Patterns            | ⚔Attack         | [📝TKDD](https://dl.acm.org/doi/10.1145/3394520)                  |                                                                                                  |   2020 |
|  5 | Scalable Attack on Graph Data by Injecting Vicious Nodes                                  | ⚔Attack         | [📝ECML-PKDD](https://arxiv.org/abs/2004.13825)                   |                                                                                                  |   2020 |
|  6 | Attackability Characterization of Adversarial Evasion Attack on Discrete Data             | ⚔Attack         | [📝KDD](https://dl.acm.org/doi/10.1145/3394486.3403194)           |                                                                                                  |   2020 |
|  7 | Adversarial Attacks on Neural Networks for Graph Data                                     | ⚔Attack         | [📝KDD](https://arxiv.org/abs/1805.07984)                         | [:octocat:Code](https://github.com/danielzuegner/nettack)                                        |   2018 |
|  8 | Robust Detection of Adaptive Spammers by Nash Reinforcement Learning                      | 🛡Defense        | [📝KDD](https://arxiv.org/abs/2006.06069)                         | [:octocat:Code](https://github.com/YingtongDou/Nash-Detect)                                      |   2020 |
|  9 | Graph Structure Learning for Robust Graph Neural Networks                                 | 🛡Defense        | [📝KDD](https://arxiv.org/abs/2005.10203)                         | [:octocat:Code](https://github.com/DSE-MSU/DeepRobust)                                           |   2020 |
| 10 | Robust Training of Graph Convolutional Networks via Latent Perturbation                   | 🛡Defense        | [📝ECML-PKDD](https://www.cs.uic.edu/~zhangx/papers/JinZha20.pdf) |                                                                                                  |   2020 |
| 11 | Improving Robustness to Attacks Against Vertex Classification                             | 🛡Defense        | [📝MLG@KDD](http://eliassi.org/papers/benmiller-mlg2019.pdf)      |                                                                                                  |   2019 |
| 12 | Robust Graph Convolutional Networks Against Adversarial Attacks                           | 🛡Defense        | [📝KDD](http://pengcui.thumedialab.com/papers/RGCN.pdf)           | [:octocat:Code](https://github.com/thumanlab/nrlweb/blob/master/static/assets/download/RGCN.zip) |   2019 |
| 13 | Certified Robustness of Graph Neural Networks against Adversarial Structural Perturbation | 🔐Certification | [KDD'2021](https://dl.acm.org/doi/abs/10.1145/3447548.3467295)    | [:octocat:Code](https://github.com/binghuiwang/CertifyGNN)                                       |   2021 |
| 14 | Certifiable Robustness of Graph Convolutional Networks under Structure Perturbation       | 🔐Certification | [📝KDD'2020](https://dl.acm.org/doi/10.1145/3394486.3403217)      | [:octocat:Code](https://github.com/danielzuegner/robust-gcn-structure)                           |   2020 |
| 15 | Certifiable Robustness and Robust Training for Graph Convolutional Networks               | 🔐Certification | [📝KDD'2019](https://arxiv.org/abs/1906.12269)                    | [:octocat:Code](https://www.kdd.in.tum.de/research/robust-gcn/)                                  |   2019 |
| 16 | Stability and Generalization of Graph Convolutional Neural Networks                       | ⚖Stability      | [📝KDD'2019](https://arxiv.org/abs/1905.01004)                    | [:octocat:Code](https://github.com/raspberryice/ala-gcn)                                         |   2019 |
| 17 | Adversarial Attacks and Defenses on Graphs: A Review, A Tool and Empirical Studies        | 📃Survey        | [📝SIGKDD Explorations'2021](https://arxiv.org/abs/2003.00653)    |                                                                                                  |   2021 |
# ICML
|    | Title                                                                                                                  | Type            | Venue                                                                                                | Code                                                                    |   Year |
|---:|:-----------------------------------------------------------------------------------------------------------------------|:----------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------|-------:|
|  0 | Practical Adversarial Attacks on Graph Neural Networks                                                                 | ⚔Attack         | [📝ICML Workshop](https://grlplus.github.io/papers/8.pdf)                                            |                                                                         |   2020 |
|  1 | Adversarial Attacks on Node Embeddings via Graph Poisoning                                                             | ⚔Attack         | [📝ICML](https://arxiv.org/abs/1809.01093)                                                           | [:octocat:Code](https://github.com/abojchevski/node_embedding_attack)   |   2019 |
|  2 | Adversarial Attack on Graph Structured Data                                                                            | ⚔Attack         | [📝ICML](https://arxiv.org/abs/1806.02371)                                                           | [:octocat:Code](https://github.com/Hanjun-Dai/graph_adversarial_attack) |   2018 |
|  3 | Integrated Defense for Resilient Graph Matching                                                                        | 🛡Defense        | [📝ICML](http://proceedings.mlr.press/v139/ren21c/ren21c.pdf)                                        |                                                                         |   2021 |
|  4 | Information Obfuscation of Graph Neural Network                                                                        | 🛡Defense        | [📝ICML](https://arxiv.org/pdf/2009.13504.pdf)                                                       | [:octocat:Code](https://github.com/liaopeiyuan/GAL)                     |   2021 |
|  5 | Elastic Graph Neural Networks                                                                                          | 🛡Defense        | [📝ICML](http://proceedings.mlr.press/v139/liu21k/liu21k.pdf)                                        | [:octocat:Code](https://github.com/lxiaorui/ElasticGNN)                 |   2021 |
|  6 | Expressive 1-Lipschitz Neural Networks for Robust Multiple Graph Learning against Adversarial Attacks                  | 🛡Defense        | [📝ICML](http://proceedings.mlr.press/v139/zhao21e.html)                                             |                                                                         |   2021 |
|  7 | Robust Graph Representation Learning via Neural Sparsification                                                         | 🛡Defense        | [📝ICML](https://proceedings.icml.cc/static/paper_files/icml/2020/2611-Paper.pdf)                    |                                                                         |   2020 |
|  8 | Batch Virtual Adversarial Training for Graph Convolutional Networks                                                    | 🛡Defense        | [📝ICML](https://arxiv.org/abs/1902.09192)                                                           | [:octocat:Code](https://github.com/thudzj/BVAT)                         |   2019 |
|  9 | Latent Adversarial Training of Graph Convolution Networks                                                              | 🛡Defense        | [📝LRGSD@ICML](https://graphreason.github.io/papers/35.pdf)                                          | [:octocat:Code](https://github.com/cshjin/LATGCN)                       |   2019 |
| 10 | Efficient Robustness Certificates for Discrete Data: Sparsity - Aware Randomized Smoothing for Graphs, Images and More | 🔐Certification | [📝ICML'2020](https://proceedings.icml.cc/book/2020/file/4f7b884f2445ef08da9bbc77b028722c-Paper.pdf) | [:octocat:Code](https://github.com/abojchevski/sparse_smoothing)        |   2020 |
# TKDE
|    | Title                                                                                    | Type     | Venue                                      | Code                                                      |   Year |
|---:|:-----------------------------------------------------------------------------------------|:---------|:-------------------------------------------|:----------------------------------------------------------|-------:|
|  0 | Adversarial Attack on Large Scale Graph                                                  | ⚔Attack  | [📝TKDE](https://arxiv.org/abs/2009.03488) | [:octocat:Code](https://github.com/EdisonLeeeee/SGAttack) |   2021 |
|  1 | NetFense: Adversarial Defenses against Privacy Attacks on Neural Networks for Graph Data | 🛡Defense | [📝TKDE](https://arxiv.org/abs/2106.11865) | [:octocat:Code](https://github.com/ICHproject/NetFense)   |   2021 |
|  2 | Graph Adversarial Training: Dynamically Regularizing Based on Graph Structure            | 🛡Defense | [📝TKDE](https://arxiv.org/abs/1902.08226) | [:octocat:Code](https://github.com/fulifeng/GraphAT)      |   2019 |
# CIKM
|    | Title                                                                                                                           | Type     | Venue                                                        | Code                                                      |   Year |
|---:|:--------------------------------------------------------------------------------------------------------------------------------|:---------|:-------------------------------------------------------------|:----------------------------------------------------------|-------:|
|  0 | A Graph Matching Attack on Privacy-Preserving Record Linkage                                                                    | ⚔Attack  | [📝CIKM](https://dl.acm.org/doi/abs/10.1145/3340531.3411931) |                                                           |   2020 |
|  1 | αCyber: Enhancing Robustness of Android Malware Detection System against Adversarial Attacks on Heterogeneous Graph based Model | ⚔Attack  | [📝CIKM](https://dl.acm.org/doi/10.1145/3357384.3357875)     |                                                           |   2019 |
|  2 | A Feature-Importance-Aware and Robust Aggregator for GCN                                                                        | 🛡Defense | [📝CIKM](https://dl.acm.org/doi/abs/10.1145/3340531.3411983) | [:octocat:Code](https://github.com/LiZhang-github/LA-GCN) |   2020 |
|  3 | Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters                                             | 🛡Defense | [📝CIKM](https://arxiv.org/abs/2008.08692)                   | [:octocat:Code](https://github.com/safe-graph/DGFraud)    |   2020 |
|  4 | αCyber: Enhancing Robustness of Android Malware Detection System against Adversarial Attacks on Heterogeneous Graph based Model | 🛡Defense | [📝CIKM](https://dl.acm.org/doi/10.1145/3357384.3357875)     |                                                           |   2019 |
# WSDM
|    | Title                                                                       | Type            | Venue                                                        | Code                                                      |   Year |
|---:|:----------------------------------------------------------------------------|:----------------|:-------------------------------------------------------------|:----------------------------------------------------------|-------:|
|  0 | Learning to Drop: Robust Graph Neural Network via Topological Denoising     | 🛡Defense        | [📝WSDM](https://arxiv.org/abs/2011.07057)                   | [:octocat:Code](https://github.com/flyingdoog/PTDNet)     |   2021 |
|  1 | Node Similarity Preserving Graph Convolutional Networks                     | 🛡Defense        | [📝WSDM](https://arxiv.org/abs/2011.09643)                   | [:octocat:Code](https://github.com/ChandlerBang/SimP-GCN) |   2021 |
|  2 | Transferring Robustness for Graph Neural Network Against Poisoning Attacks  | 🛡Defense        | [📝WSDM](https://arxiv.org/abs/1908.07558)                   | [:octocat:Code](https://github.com/tangxianfeng/PA-GNN)   |   2020 |
|  3 | All You Need Is Low (Rank): Defending Against Adversarial Attacks on Graphs | 🛡Defense        | [📝WSDM](https://dl.acm.org/doi/abs/10.1145/3336191.3371789) | [:octocat:Code](https://github.com/DSE-MSU/DeepRobust)    |   2020 |
|  4 | Adversarial Immunization for Improving Certifiable Robustness on Graphs     | 🔐Certification | [📝WSDM'2021](https://arxiv.org/abs/2007.09647)              |                                                           |   2021 |
# NeurIPS
|    | Title                                                                                                        | Type            | Venue                                                                                            | Code                                                                              |   Year |
|---:|:-------------------------------------------------------------------------------------------------------------|:----------------|:-------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------|-------:|
|  0 | Adversarial Attacks on Deep Graph Matching                                                                   | ⚔Attack         | [📝NeurIPS](https://papers.nips.cc/paper/2020/file/ef126722e64e98d1c33933783e52eafc-Paper.pdf)   |                                                                                   |   2020 |
|  1 | Black-Box Adversarial Attacks on Graph Neural Networks with Limited Node Access                              | ⚔Attack         | [📝NeurIPS](https://arxiv.org/abs/2006.05057)                                                    |                                                                                   |   2020 |
|  2 | Towards More Practical Adversarial Attacks on Graph Neural Networks                                          | ⚔Attack         | [📝NeurIPS](https://arxiv.org/abs/2006.05057)                                                    | [:octocat:Code](https://github.com/Mark12Ding/GNN-Practical-Attack)               |   2020 |
|  3 | A Unified Framework for Data Poisoning Attack to Graph-based Semi-supervised Learning                        | ⚔Attack         | [📝NeurIPS](https://arxiv.org/abs/1910.14147)                                                    | [:octocat:Code](https://github.com/xuanqing94/AdvSSL)                             |   2019 |
|  4 | Provable Overlapping Community Detection in Weighted Graphs                                                  | 🛡Defense        | [📝NeurIPS](https://arxiv.org/abs/2004.07150)                                                    |                                                                                   |   2020 |
|  5 | Variational Inference for Graph Convolutional Networks in the Absence of Graph Data and Adversarial Settings | 🛡Defense        | [📝NeurIPS](https://arxiv.org/abs/1906.01852)                                                    | [:octocat:Code](https://github.com/ebonilla/VGCN)                                 |   2020 |
|  6 | Graph Random Neural Networks for Semi-Supervised Learning on Graphs                                          | 🛡Defense        | [📝NeurIPS](https://arxiv.org/abs/2005.11079)                                                    | [:octocat:Code](https://github.com/Grand20/grand)                                 |   2020 |
|  7 | Reliable Graph Neural Networks via Robust Aggregation                                                        | 🛡Defense        | [📝NeurIPS](https://arxiv.org/abs/2010.15651)                                                    | [:octocat:Code](https://github.com/sigeisler/reliable_gnn_via_robust_aggregation) |   2020 |
|  8 | Iterative Deep Graph Learning for Graph Neural Networks: Better and Robust Node Embeddings                   | 🛡Defense        | [📝NeurIPS](https://arxiv.org/abs/2006.13009)                                                    | [:octocat:Code](https://github.com/hugochan/IDGL)                                 |   2020 |
|  9 | Community detection in sparse time-evolving graphs with a dynamical Bethe-Hessian                            | 🛡Defense        | [📝NeurIPS](https://arxiv.org/abs/2006.04510)                                                    |                                                                                   |   2020 |
| 10 | Graph Information Bottleneck                                                                                 | 🛡Defense        | [📝NeurIPS](https://arxiv.org/abs/2010.12811)                                                    | [:octocat:Code](http://snap.stanford.edu/gib/)                                    |   2020 |
| 11 | Graph Contrastive Learning with Augmentations                                                                | 🛡Defense        | [📝NeurIPS](https://arxiv.org/abs/2010.13902)                                                    | [:octocat:Code](https://github.com/Shen-Lab/GraphCL)                              |   2020 |
| 12 | GNNGuard: Defending Graph Neural Networks against Adversarial Attacks                                        | 🛡Defense        | [📝NeurIPS](https://arxiv.org/abs/2006.08149)                                                    | [:octocat:Code](https://github.com/mims-harvard/GNNGuard)                         |   2020 |
| 13 | Certified Robustness of Graph Convolution Networks for Graph Classification under Topological Attacks        | 🔐Certification | [📝NeurIPS'2020](https://www.cs.uic.edu/~zhangx/papers/Jinetal20.pdf)                            | [:octocat:Code](https://github.com/RobustGraph/RoboGraph)                         |   2020 |
| 14 | Certified Robustness of Graph Classification against Topology Attack with Randomized Smoothing               | 🔐Certification | [📝NeurIPS'2020](https://arxiv.org/abs/2009.05872)                                               |                                                                                   |   2020 |
| 15 | Certifiable Robustness to Graph Perturbations                                                                | 🔐Certification | [📝NeurIPS'2019](http://papers.nips.cc/paper/9041-certifiable-robustness-to-graph-perturbations) | [:octocat:Code](https://github.com/abojchevski/graph_cert)                        |   2019 |
| 16 | Graph Robustness Benchmark: Rethinking and Benchmarking Adversarial Robustness of Graph Neural Networks      | ⚙Toolbox        | [📝NeurIPS Openreview ’2021](https://openreview.net/forum?id=pBwQ82pYha)                         | [**:octocat:Graph Robustness Benchmark (GRB)**](https://github.com/thudm/grb)     |   2021 |
# USENIX
|    | Title                                                             | Type     | Venue                                                                            | Code   |   Year |
|---:|:------------------------------------------------------------------|:---------|:---------------------------------------------------------------------------------|:-------|-------:|
|  0 | Stealing Links from Graph Neural Networks                         | ⚔Attack  | [📝USENIX Security](https://www.usenix.org/system/files/sec21summer_he.pdf)      |        |   2021 |
|  1 | Graph Backdoor                                                    | ⚔Attack  | [📝USENIX Security](https://arxiv.org/abs/2006.11890)                            |        |   2021 |
|  2 | SIGL: Securing Software Installations Through Deep Graph Learning | 🚀Others | [📝USENIX'2021](https://www.usenix.org/system/files/sec21summer_han-xueyuan.pdf) |        |   2021 |
# ICDM
|    | Title                                                                   | Type     | Venue                                                                       | Code                                               |   Year |
|---:|:------------------------------------------------------------------------|:---------|:----------------------------------------------------------------------------|:---------------------------------------------------|-------:|
|  0 | Adversarial Label-Flipping Attack and Defense for Graph Neural Networks | ⚔Attack  | [📝ICDM](http://shichuan.org/doc/97.pdf)                                    | [:octocat:Code](https://github.com/MengmeiZ/LafAK) |   2020 |
|  1 | Exploratory Adversarial Attacks on Graph Neural Networks                | ⚔Attack  | [📝ICDM](https://ieeexplore.ieee.org/document/9338329)                      | [:octocat:Code](https://github.com/EpoAtk/EpoAtk)  |   2020 |
|  2 | AANE: Anomaly Aware Network Embedding For Anomalous Link Detection      | 🛡Defense | [📝ICDM](https://ieeexplore.ieee.org/document/9338406)                      |                                                    |   2020 |
|  3 | Provably Robust Node Classification via Low-Pass Message Passing        | 🛡Defense | [📝ICDM](https://shenghua-liu.github.io/papers/icdm2020-provablerobust.pdf) |                                                    |   2020 |
|  4 | Adversarial Robustness of Similarity-Based Link Prediction              | 🛡Defense | [📝ICDM](https://arxiv.org/abs/1909.01432)                                  |                                                    |   2019 |
# Arxiv
|    | Title                                                                                                               | Type       | Venue                                                                                        | Code                                                                                                             |   Year |
|---:|:--------------------------------------------------------------------------------------------------------------------|:-----------|:---------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------|-------:|
|  0 | PATHATTACK: Attacking Shortest Paths in Complex Networks                                                            | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2104.03761)                                                  |                                                                                                                  |   2021 |
|  1 | Optimal Edge Weight Perturbations to Attack Shortest Paths                                                          | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2107.03347)                                                  |                                                                                                                  |   2021 |
|  2 | Membership Inference Attack on Graph Neural Networks                                                                | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2101.06570)                                                  |                                                                                                                  |   2021 |
|  3 | BinarizedAttack: Structural Poisoning Attacks to Graph-based Anomaly Detection                                      | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2106.09989)                                                  |                                                                                                                  |   2021 |
|  4 | Adversarial Attack on Graph Neural Networks as An Influence Maximization Problem                                    | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2106.10785)                                                  |                                                                                                                  |   2021 |
|  5 | Adversarial Attack Framework on Graph Embedding Models with Limited Knowledge                                       | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2105.12419)                                                  |                                                                                                                  |   2021 |
|  6 | Black-box Gradient Attack on Graph Neural Networks: Deeper Insights in Graph-based Attack and Defense               | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2104.15061)                                                  |                                                                                                                  |   2021 |
|  7 | Joint Detection and Localization of Stealth False Data Injection Attacks in Smart Grids using Graph Neural Networks | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2104.11846)                                                  |                                                                                                                  |   2021 |
|  8 | Adversarial Diffusion Attacks on Graph-based Traffic Prediction Models                                              | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2104.09369)                                                  | [:octocat:Code](https://github.com/LYZ98/Adversarial-Diffusion-Attacks-on-Graph-based-Traffic-Prediction-Models) |   2021 |
|  9 | Explainability-based Backdoor Attacks Against Graph Neural Networks                                                 | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2104.03674)                                                  |                                                                                                                  |   2021 |
| 10 | GraphAttacker: A General Multi-Task GraphAttack Framework                                                           | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2101.06855)                                                  | [:octocat:Code](https://github.com/honoluluuuu/GraphAttacker)                                                    |   2021 |
| 11 | Node-Level Membership Inference Attacks Against Graph Neural Networks                                               | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2102.05429)                                                  |                                                                                                                  |   2021 |
| 12 | Reinforcement Learning For Data Poisoning on Graph Neural Networks                                                  | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2102.06800)                                                  |                                                                                                                  |   2021 |
| 13 | Graphfool: Targeted Label Adversarial Attack on Graph Embedding                                                     | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2102.12284)                                                  |                                                                                                                  |   2021 |
| 14 | Preserve, Promote, or Attack? GNN Explanation via Topology Perturbation                                             | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2103.12256)                                                  |                                                                                                                  |   2021 |
| 15 | Jointly Attacking Graph Neural Network and its Explanations                                                         | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2108.03388)                                                  |                                                                                                                  |   2021 |
| 16 | Graph Stochastic Neural Networks for Semi-supervised Learning                                                       | ⚔Attack    | [📝Arxiv](https://papers.nips.cc/paper/2020/file/e586a4f55fb43a540c2e9dab45e00f53-Paper.pdf) | [:octocat:Code](https://github.com/GSNN/GSNN)                                                                    |   2021 |
| 17 | Iterative Deep Graph Learning for Graph Neural Networks: Better and Robust Node Embeddings                          | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2006.13009)                                                  | [:octocat:Code](https://github.com/hugochan/IDGL)                                                                |   2021 |
| 18 | Semantic-preserving Reinforcement Learning Attack Against Graph Neural Networks for Malware Detection               | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2009.05602)                                                  |                                                                                                                  |   2020 |
| 19 | Scalable Adversarial Attack on Graph Neural Networks with Alternating Direction Method of Multipliers               | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2009.10233)                                                  |                                                                                                                  |   2020 |
| 20 | Model Extraction Attacks on Graph Neural Networks: Taxonomy and Realization                                         | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2010.12751)                                                  |                                                                                                                  |   2020 |
| 21 | A Targeted Universal Attack on Graph Convolutional Network                                                          | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2011.14365)                                                  | [:octocat:Code](https://github.com/Nanyuu/TUA)                                                                   |   2020 |
| 22 | Query-free Black-box Adversarial Attacks on Graphs                                                                  | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2012.06757)                                                  |                                                                                                                  |   2020 |
| 23 | Reinforcement Learning-based Black-Box Evasion Attacks to Link Prediction in Dynamic Graphs                         | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2009.00163)                                                  |                                                                                                                  |   2020 |
| 24 | Efficient Evasion Attacks to Graph Neural Networks via Influence Function                                           | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2009.00203)                                                  |                                                                                                                  |   2020 |
| 25 | Adversarial Attack on Hierarchical Graph Pooling Neural Networks                                                    | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2005.11560)                                                  |                                                                                                                  |   2020 |
| 26 | MGA: Momentum Gradient Attack on Network                                                                            | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2002.11320)                                                  |                                                                                                                  |   2020 |
| 27 | Adversarial Attacks to Scale-Free Networks: Testing the Robustness of Physical Criteria                             | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2002.01249)                                                  |                                                                                                                  |   2020 |
| 28 | Graph Universal Adversarial Attacks: A Few Bad Actors Ruin Graph Learning Models                                    | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2002.04784)                                                  | [:octocat:Code](https://github.com/chisam0217/Graph-Universal-Attack)                                            |   2020 |
| 29 | Adversarial Perturbations of Opinion Dynamics in Networks                                                           | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2003.07010)                                                  |                                                                                                                  |   2020 |
| 30 | Network disruption: maximizing disagreement and polarization in social networks                                     | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/2003.08377)                                                  | [:octocat:Code](https://github.com/mayee107/network-disruption)                                                  |   2020 |
| 31 | Time-aware Gradient Attack on Dynamic Network Link Prediction                                                       | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/1911.10561)                                                  |                                                                                                                  |   2019 |
| 32 | Attacking Graph Convolutional Networks via Rewiring                                                                 | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/1906.03750)                                                  |                                                                                                                  |   2019 |
| 33 | Unsupervised Euclidean Distance Attack on Network Embedding                                                         | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/1905.11015)                                                  |                                                                                                                  |   2019 |
| 34 | Generalizable Adversarial Attacks with Latent Variable Perturbation Modelling                                       | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/1905.10864)                                                  |                                                                                                                  |   2019 |
| 35 | Vertex Nomination, Consistent Estimation, and Adversarial Modification                                              | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/1905.01776)                                                  |                                                                                                                  |   2019 |
| 36 | Multiscale Evolutionary Perturbation Attack on Community Detection                                                  | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/1910.09741)                                                  |                                                                                                                  |   2019 |
| 37 | Fake Node Attacks on Graph Convolutional Networks                                                                   | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/1810.10751)                                                  |                                                                                                                  |   2018 |
| 38 | Data Poisoning Attack against Unsupervised Node Embedding Methods                                                   | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/1810.12881)                                                  |                                                                                                                  |   2018 |
| 39 | Fast Gradient Attack on Network Embedding                                                                           | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/1809.02797)                                                  |                                                                                                                  |   2018 |
| 40 | Attack Tolerance of Link Prediction Algorithms: How to Hide Your Relations in a Social Network                      | ⚔Attack    | [📝Arxiv](https://arxiv.org/abs/1809.00152)                                                  |                                                                                                                  |   2018 |
| 41 | How effective are Graph Neural Networks in Fraud Detection for Network Data?                                        | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2105.14568)                                                  |                                                                                                                  |   2021 |
| 42 | Graph Sanitation with Application to Node Classification                                                            | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2105.09384)                                                  |                                                                                                                  |   2021 |
| 43 | A Robust and Generalized Framework for Adversarial Graph Embedding                                                  | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2105.10651)                                                  | [:octocat:Code](https://github.com/RingBDStack/AGE)                                                              |   2021 |
| 44 | Adversarial Graph Augmentation to Improve Graph Contrastive Learning                                                | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2106.05819)                                                  |                                                                                                                  |   2021 |
| 45 | Improving Robustness of Graph Neural Networks with Heterophily-Inspired Designs                                     | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2106.07767)                                                  |                                                                                                                  |   2021 |
| 46 | Robust Counterfactual Explanations on Graph Neural Networks                                                         | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2107.04086)                                                  |                                                                                                                  |   2021 |
| 47 | Robust Graph Learning Under Wasserstein Uncertainty                                                                 | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2105.04210)                                                  |                                                                                                                  |   2021 |
| 48 | Towards Robust Graph Contrastive Learning                                                                           | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2102.13085)                                                  |                                                                                                                  |   2021 |
| 49 | Interpretable Stability Bounds for Spectral Graph Filters                                                           | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2102.09587)                                                  |                                                                                                                  |   2021 |
| 50 | Unified Robust Training for Graph NeuralNetworks against Label Noise                                                | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2103.03414)                                                  |                                                                                                                  |   2021 |
| 51 | An Introduction to Robust Graph Convolutional Networks                                                              | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2103.14807)                                                  |                                                                                                                  |   2021 |
| 52 | E-GraphSAGE: A Graph Neural Network based Intrusion Detection System                                                | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2103.16329)                                                  |                                                                                                                  |   2021 |
| 53 | Spatio-Temporal Sparsification for General Robust Graph Convolution Networks                                        | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2103.12256)                                                  |                                                                                                                  |   2021 |
| 54 | Unveiling the potential of Graph Neural Networks for robust Intrusion Detection                                     | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2107.14747)                                                  | [:octocat:Code](https://github.com/BNN-UPC/GNN-NIDS)                                                             |   2021 |
| 55 | Adversarial Robustness of Probabilistic Network Embedding for Link Prediction                                       | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2107.01936)                                                  |                                                                                                                  |   2021 |
| 56 | Node Copying for Protection Against Graph Neural Network Topology Attacks                                           | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2007.06704)                                                  |                                                                                                                  |   2020 |
| 57 | Unsupervised Adversarially-Robust Representation Learning on Graphs                                                 | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2012.02486)                                                  |                                                                                                                  |   2020 |
| 58 | Anti-perturbation of Online Social Networks by Graph Label Transition                                               | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2010.14121)                                                  |                                                                                                                  |   2020 |
| 59 | I-GCN: Robust Graph Convolutional Network via Influence Mechanism                                                   | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2012.06110)                                                  |                                                                                                                  |   2020 |
| 60 | RoGAT: a robust GNN combined revised GAT with adjusted graphs                                                       | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2009.13038)                                                  |                                                                                                                  |   2020 |
| 61 | ResGCN: Attention-based Deep Residual Modeling for Anomaly Detection on Attributed Networks                         | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2009.14738)                                                  |                                                                                                                  |   2020 |
| 62 | Adversarial Perturbations of Opinion Dynamics in Networks                                                           | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2003.07010)                                                  |                                                                                                                  |   2020 |
| 63 | Adversarial Privacy Preserving Graph Embedding against Inference Attack                                             | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2008.13072)                                                  | [:octocat:Code](https://github.com/uJ62JHD/Privacy-Preserving-Social-Network-Embedding)                          |   2020 |
| 64 | Topological Effects on Attacks Against Vertex Classification                                                        | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2003.05822)                                                  |                                                                                                                  |   2020 |
| 65 | Tensor Graph Convolutional Networks for Multi-relational and Robust Learning                                        | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2003.07729)                                                  |                                                                                                                  |   2020 |
| 66 | DefenseVGAE: Defending against Adversarial Attacks on Graph Data via a Variational Graph Autoencoder                | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2006.08900)                                                  | [:octocat:Code](https://github.com/zhangao520/defense-vgae)                                                      |   2020 |
| 67 | Dynamic Knowledge Graph-based Dialogue Generation with Improved Adversarial Meta-Learning                           | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/2004.08833)                                                  |                                                                                                                  |   2020 |
| 68 | Target Defense Against Link-Prediction-Based Attacks via Evolutionary Perturbations                                 | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/1809.05912)                                                  |                                                                                                                  |   2019 |
| 69 | Examining Adversarial Learning against Graph-based IoT Malware Detection Systems                                    | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/1902.04416)                                                  |                                                                                                                  |   2019 |
| 70 | Adversarial Embedding: A robust and elusive Steganography and Watermarking technique                                | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/1912.01487)                                                  |                                                                                                                  |   2019 |
| 71 | Graph Interpolating Activation Improves Both Natural and Robust Accuracies in Data-Efficient Deep Learning          | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/1907.06800)                                                  | [:octocat:Code](https://github.com/BaoWangMath/DNN-DataDependentActivation)                                      |   2019 |
| 72 | Adversarial Defense Framework for Graph Neural Network                                                              | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/1905.03679)                                                  |                                                                                                                  |   2019 |
| 73 | GraphSAC: Detecting anomalies in large-scale graphs                                                                 | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/1910.09589)                                                  |                                                                                                                  |   2019 |
| 74 | Edge Dithering for Robust Adaptive Graph Convolutional Networks                                                     | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/1910.09590)                                                  |                                                                                                                  |   2019 |
| 75 | Can Adversarial Network Attack be Defended?                                                                         | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/1903.05994)                                                  |                                                                                                                  |   2019 |
| 76 | GraphDefense: Towards Robust Graph Convolutional Networks                                                           | 🛡Defense   | [📝Arxiv](https://arxiv.org/abs/1911.04429)                                                  |                                                                                                                  |   2019 |
| 77 | Shift-Robust GNNs: Overcoming the Limitations of Localized Graph Training data                                      | ⚖Stability | [📝Arxiv'2021](https://www.ijcai.org/Proceedings/2020/181)                                   |                                                                                                                  |   2021 |
| 78 | Stability of Graph Convolutional Neural Networks to Stochastic Perturbations                                        | ⚖Stability | [📝Arxiv'2021](https://arxiv.org/abs/2106.10526)                                             |                                                                                                                  |   2021 |
| 79 | Graph and Graphon Neural Network Stability                                                                          | ⚖Stability | [📝Arxiv'2020](https://arxiv.org/abs/2008.01767)                                             |                                                                                                                  |   2020 |
| 80 | On the Stability of Graph Convolutional Neural Networks under Edge Rewiring                                         | ⚖Stability | [📝Arxiv'2020](https://arxiv.org/abs/2010.13747)                                             |                                                                                                                  |   2020 |
| 81 | Graph Neural Networks: Architectures, Stability and Transferability                                                 | ⚖Stability | [📝Arxiv'2020](https://arxiv.org/abs/2008.01767)                                             |                                                                                                                  |   2020 |
| 82 | Should Graph Convolution Trust Neighbors? A Simple Causal Inference Method                                          | ⚖Stability | [📝Arxiv'2020](https://arxiv.org/abs/2010.11797)                                             |                                                                                                                  |   2020 |
| 83 | Stability Properties of Graph Neural Networks                                                                       | ⚖Stability | [📝Arxiv'2019](https://arxiv.org/abs/1905.04497)                                             |                                                                                                                  |   2019 |
| 84 | FLAG: Adversarial Data Augmentation for Graph Neural Networks                                                       | 🚀Others   | [📝Arxiv'2020](https://arxiv.org/abs/2010.09891)                                             | [:octocat:Code](https://github.com/devnkong/FLAG)                                                                |   2020 |
| 85 | Dynamic Knowledge Graph-based Dialogue Generation with Improved Adversarial Meta-Learning                           | 🚀Others   | [📝Arxiv'2020](https://arxiv.org/abs/2004.08833)                                             |                                                                                                                  |   2020 |
| 86 | Watermarking Graph Neural Networks by Random Graphs                                                                 | 🚀Others   | [📝Arxiv'2020](https://arxiv.org/abs/2011.00512)                                             |                                                                                                                  |   2020 |
| 87 | Graph Neural Networks Taxonomy, Advances and Trends                                                                 | 📃Survey   | [📝Arxiv'2020](https://arxiv.org/abs/2012.08752)                                             |                                                                                                                  |   2020 |
| 88 | A Survey of Adversarial Learning on Graph                                                                           | 📃Survey   | [📝Arxiv'2020](https://arxiv.org/abs/2003.05730)                                             |                                                                                                                  |   2020 |
| 89 | Adversarial Attacks and Defenses on Graphs: A Review and Empirical Study                                            | 📃Survey   | [📝Arxiv'2020](https://arxiv.org/abs/2003.00653)                                             |                                                                                                                  |   2020 |
| 90 | Adversarial Attacks and Defenses in Images, Graphs and Text: A Review                                               | 📃Survey   | [📝Arxiv'2019](https://arxiv.org/abs/1909.08072)                                             |                                                                                                                  |   2019 |
| 91 | Adversarial Attack and Defense on Graph Data: A Survey                                                              | 📃Survey   | [📝Arxiv'2018](https://arxiv.org/abs/1812.10528)                                             |                                                                                                                  |   2018 |
| 92 | Deep Learning on Graphs A Survey                                                                                    | 📃Survey   | [📝Arxiv'2018](https://arxiv.org/abs/1812.04202)                                             |                                                                                                                  |   2018 |
| 93 | Evaluating Graph Vulnerability and Robustness using TIGER                                                           | ⚙Toolbox   | [📝Arxiv‘2021](https://arxiv.org/abs/2006.05648)                                             | [**:octocat:TIGER**](https://github.com/safreita1/TIGER)                                                         |   2021 |
# UAI
|    | Title                                                      | Type     | Venue                                          | Code                                                    |   Year |
|---:|:-----------------------------------------------------------|:---------|:-----------------------------------------------|:--------------------------------------------------------|-------:|
|  0 | Adversarial Sets for Regularising Neural Link Predictors   | ⚔Attack  | [📝UAI](https://arxiv.org/abs/1707.07596)      | [:octocat:Code](https://github.com/uclmr/inferbeddings) |   2017 |
|  1 | Adversarial Sets for Regularising Neural Link Predictors   | 🛡Defense | [📝UAI](https://arxiv.org/abs/1707.07596)      | [:octocat:Code](https://github.com/uclmr/inferbeddings) |   2017 |
|  2 | Generating Adversarial Examples with Graph Neural Networks | 🚀Others | [📝UAI'2021](https://arxiv.org/abs/2105.14644) |                                                         |   2021 |
# ICSE
|    | Title                                                                                                                   | Type     | Venue                                                                     | Code                                                                      |   Year |
|---:|:------------------------------------------------------------------------------------------------------------------------|:---------|:--------------------------------------------------------------------------|:--------------------------------------------------------------------------|-------:|
|  0 | GraphGallery: A Platform for Fast Benchmarking and Easy Development of Graph Neural Networks Based Intelligent Software | ⚙Toolbox | [📝ICSE Demo‘2021](https://ieeexplore.ieee.org/abstract/document/9402641) | [**:octocat:GraphGallery**](https://github.com/EdisonLeeeee/GraphGallery) |   2021 |
# ECAI
|    | Title                                                                                   | Type            | Venue                                                 | Code   |   Year |
|---:|:----------------------------------------------------------------------------------------|:----------------|:------------------------------------------------------|:-------|-------:|
|  0 | Abstract Interpretation based Robustness Certification for Graph Convolutional Networks | 🔐Certification | [📝ECAI'2020](http://ecai2020.eu/papers/31_paper.pdf) |        |   2020 |
# Others
|    | Title                                                                                                    | Type            | Venue                                                                                                                                                                         | Code                                                                            |   Year |
|---:|:---------------------------------------------------------------------------------------------------------|:----------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------|-------:|
|  0 | Structack: Structure-based Adversarial Attacks on Graph Neural Networks                                  | ⚔Attack         | [📝ACM Hypertext](https://arxiv.org/abs/2107.11327)                                                                                                                           | [:octocat:Code](https://github.com/sqrhussain/structack)                        |   2021 |
|  1 | GReady for Emerging Threats to Recommender Systems? A Graph Convolution-based Generative Shilling Attack | ⚔Attack         | [📝Information Sciences](https://arxiv.org/abs/2107.10457)                                                                                                                    |                                                                                 |   2021 |
|  2 | Universal Spectral Adversarial Attacks for Deformable Shapes                                             | ⚔Attack         | [📝CVPR](https://arxiv.org/abs/2104.03356)                                                                                                                                    |                                                                                 |   2021 |
|  3 | Towards Revealing Parallel Adversarial Attack on Politician Socialnet of Graph Structure                 | ⚔Attack         | [📝Security and Communication Networks](https://www.hindawi.com/journals/scn/2021/6631247)                                                                                    |                                                                                 |   2021 |
|  4 | Network Embedding Attack: An Euclidean Distance Based Method                                             | ⚔Attack         | [📝MDATA](https://link.springer.com/chapter/10.1007%2F978-3-030-71590-8_8)                                                                                                    |                                                                                 |   2021 |
|  5 | Adaptive Adversarial Attack on Graph Embedding via GAN                                                   | ⚔Attack         | [📝SocialSec](https://link.springer.com/chapter/10.1007/978-981-15-9031-3_7)                                                                                                  |                                                                                 |   2020 |
|  6 | Attacking Graph-Based Classification without Changing Existing Connections                               | ⚔Attack         | [📝ACSAC](https://cse.sc.edu/~zeng1/papers/2020-acsac-graph.pdf)                                                                                                              |                                                                                 |   2020 |
|  7 | Cross Entropy Attack on Deep Graph Infomax                                                               | ⚔Attack         | [📝IEEE ISCAS](https://ieeexplore.ieee.org/document/9180817)                                                                                                                  |                                                                                 |   2020 |
|  8 | Link Prediction Adversarial Attack Via Iterative Gradient Attack                                         | ⚔Attack         | [📝IEEE Trans](https://ieeexplore.ieee.org/abstract/document/9141291)                                                                                                         |                                                                                 |   2020 |
|  9 | Manipulating Node Similarity Measures in Networks                                                        | ⚔Attack         | [📝AAMAS](https://arxiv.org/abs/1910.11529)                                                                                                                                   |                                                                                 |   2020 |
| 10 | Indirect Adversarial Attacks via Poisoning Neighbors for Graph Convolutional Networks                    | ⚔Attack         | [📝BigData](https://arxiv.org/abs/2002.08012)                                                                                                                                 |                                                                                 |   2020 |
| 11 | Adversarial Attacks on Link Prediction Algorithms Based on Graph Neural Networks                         | ⚔Attack         | [📝Asia CCS](https://iqua.ece.toronto.edu/papers/wlin-asiaccs20.pdf)                                                                                                          |                                                                                 |   2020 |
| 12 | Adversarial attack on BC classification for scale-free networks                                          | ⚔Attack         | [📝AIP Chaos](https://aip.scitation.org/doi/10.1063/5.0003707)                                                                                                                |                                                                                 |   2020 |
| 13 | Network Structural Vulnerability A Multi-Objective Attacker Perspective                                  | ⚔Attack         | [📝IEEE Trans](https://ieeexplore.ieee.org/document/8275029)                                                                                                                  |                                                                                 |   2019 |
| 14 | GA Based Q-Attack on Community Detection                                                                 | ⚔Attack         | [📝TCSS](https://arxiv.org/abs/1811.00430)                                                                                                                                    |                                                                                 |   2019 |
| 15 | Attacking Graph-based Classification via Manipulating the Graph Structure                                | ⚔Attack         | [📝CCS](https://arxiv.org/abs/1903.00553)                                                                                                                                     |                                                                                 |   2019 |
| 16 | Hiding Individuals and Communities in a Social Network                                                   | ⚔Attack         | [📝Nature Human Behavior](https://arxiv.org/abs/1608.00375)                                                                                                                   |                                                                                 |   2018 |
| 17 | Attacking Similarity-Based Link Prediction in Social Networks                                            | ⚔Attack         | [📝AAMAS](https://arxiv.org/abs/1809.08368)                                                                                                                                   |                                                                                 |   2018 |
| 18 | Practical Attacks Against Graph-based Clustering                                                         | ⚔Attack         | [📝CCS](https://arxiv.org/abs/1708.09056)                                                                                                                                     |                                                                                 |   2017 |
| 19 | Unveiling Anomalous Nodes Via Random Sampling and Consensus on Graphs                                    | 🛡Defense        | [📝ICASSP](https://ieeexplore.ieee.org/abstract/document/9414953)                                                                                                             |                                                                                 |   2021 |
| 20 | On Generalization of Graph Autoencoders with Adversarial Training                                        | 🛡Defense        | [📝ECML](https://arxiv.org/abs/2107.02658)                                                                                                                                    |                                                                                 |   2021 |
| 21 | DeepInsight: Interpretability Assisting Detection of Adversarial Samples on Graphs                       | 🛡Defense        | [📝ECML](https://arxiv.org/abs/2106.09501)                                                                                                                                    |                                                                                 |   2021 |
| 22 | Enhancing Robustness and Resilience of Multiplex Networks Against Node-Community Cascading Failures      | 🛡Defense        | [📝IEEE TSMC](https://ieeexplore.ieee.org/abstract/document/9415463)                                                                                                          |                                                                                 |   2021 |
| 23 | Robust graph convolutional networks with directional graph adversarial training                          | 🛡Defense        | [📝Applied Intelligence](https://link.springer.com/article/10.1007/s10489-021-02272-y)                                                                                        |                                                                                 |   2021 |
| 24 | Detection and Defense of Topological Adversarial Attacks on Graphs                                       | 🛡Defense        | [📝AISTATS](http://proceedings.mlr.press/v130/zhang21i.html)                                                                                                                  |                                                                                 |   2021 |
| 25 | A Novel Defending Scheme for Graph-Based Classification Against Graph Structure Manipulating Attack      | 🛡Defense        | [📝SocialSec](https://link.springer.com/chapter/10.1007/978-981-15-9031-3_26)                                                                                                 |                                                                                 |   2020 |
| 26 | Adversarial Detection on Graph Structured Data                                                           | 🛡Defense        | [📝PPMLP](https://dl.acm.org/doi/abs/10.1145/3411501.3419424)                                                                                                                 |                                                                                 |   2020 |
| 27 | Learning Graph Embedding with Adversarial Training Methods                                               | 🛡Defense        | [📝IEEE Transactions on Cybernetics](https://arxiv.org/abs/1901.01250)                                                                                                        |                                                                                 |   2020 |
| 28 | Smoothing Adversarial Training for GNN                                                                   | 🛡Defense        | [📝IEEE TCSS](https://ieeexplore.ieee.org/abstract/document/9305289?casa_token=fTXIL3hT1yIAAAAA:I4fn-GlF0PIwzPRC87SayRi5_pi2ZDDuSancEsY96A4O4bUBEsp0hSYMNJVGVzMgBWxycYN9qu6D) |                                                                                 |   2020 |
| 29 | Graph Structure Reshaping Against Adversarial Attacks on Graph Neural Networks                           | 🛡Defense        | [📝None](None)                                                                                                                                                                | [:octocat:Code](https://github.com/GraphReshape/GraphReshape)                   |   2020 |
| 30 | Robust Graph Learning From Noisy Data                                                                    | 🛡Defense        | [📝IEEE Trans](https://ieeexplore.ieee.org/abstract/document/8605364)                                                                                                         |                                                                                 |   2020 |
| 31 | How Robust Are Graph Neural Networks to Structural Noise?                                                | 🛡Defense        | [📝DLGMA](https://arxiv.org/abs/1912.10206)                                                                                                                                   |                                                                                 |   2020 |
| 32 | On The Stability of Polynomial Spectral Graph Filters                                                    | 🛡Defense        | [📝ICASSP](https://ieeexplore.ieee.org/abstract/document/9054072)                                                                                                             | [:octocat:Code](https://github.com/henrykenlay/spgf)                            |   2020 |
| 33 | Towards an Efficient and General Framework of Robust Training for Graph Neural Networks                  | 🛡Defense        | [📝ICASSP](https://arxiv.org/abs/2002.10947)                                                                                                                                  |                                                                                 |   2020 |
| 34 | Robust Collective Classification against Structural Attacks                                              | 🛡Defense        | [📝Preprint](http://www.auai.org/uai2020/proceedings/119_main_paper.pdf)                                                                                                      |                                                                                 |   2020 |
| 35 | Virtual Adversarial Training on Graph Convolutional Networks in Node Classification                      | 🛡Defense        | [📝PRCV](https://arxiv.org/abs/1902.11045)                                                                                                                                    |                                                                                 |   2019 |
| 36 | Investigating Robustness and Interpretability of Link Prediction via Adversarial Modifications           | 🛡Defense        | [📝NAACL](https://arxiv.org/abs/1905.00563)                                                                                                                                   | [:octocat:Code](https://github.com/pouyapez/criage)                             |   2019 |
| 37 | Adversarial Personalized Ranking for Recommendation                                                      | 🛡Defense        | [📝SIGIR](https://dl.acm.org/citation.cfm?id=3209981)                                                                                                                         | [:octocat:Code](https://github.com/hexiangnan/adversarial_personalized_ranking) |   2018 |
| 38 | Robust Certification for Laplace Learning on Geometric Graphs                                            | 🔐Certification | [📝MSML’2021](https://arxiv.org/abs/2104.10837)                                                                                                                               |                                                                                 |   2021 |
| 39 | Stability of Graph Neural Networks to Relative Perturbations                                             | ⚖Stability      | [📝ICASSP'2020](https://ieeexplore.ieee.org/document/9054341)                                                                                                                 |                                                                                 |   2020 |
| 40 | Perturbation Sensitivity of GNNs                                                                         | 🚀Others        | [📝cs224w'2019](http://snap.stanford.edu/class/cs224w-2019/project/26424139.pdf)                                                                                              |                                                                                 |   2019 |
